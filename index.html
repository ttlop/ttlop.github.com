<!DOCTYPE html>
<html>

<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?639ab28f32e0029ed25324113f0ff34a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


<head>
  <meta charset="utf-8">
  
  <title>运维生存时间</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="运维 生存时间 ttl op oa">
<meta property="og:type" content="website">
<meta property="og:title" content="运维生存时间">
<meta property="og:url" content="http://ttlop.com/index.html">
<meta property="og:site_name" content="运维生存时间">
<meta property="og:description" content="运维 生存时间 ttl op oa">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="运维生存时间">
<meta name="twitter:description" content="运维 生存时间 ttl op oa">
  
    <link rel="alternate" href="/atom.xml" title="运维生存时间" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">运维生存时间</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">业精于勤而荒于嬉，行成于思而毁于随</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/About">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://ttlop.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-华为S系列交换机配置SSH登录" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/16/华为S系列交换机配置SSH登录/" class="article-date">
  <time datetime="2017-03-16T04:22:36.000Z" itemprop="datePublished">2017-03-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/HUAWEI/">HUAWEI</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/16/华为S系列交换机配置SSH登录/">华为S系列交换机配置SSH登录</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>配置思路</strong></p>
<ul>
<li>配置VTY用户界面</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">system-view</span><br><span class="line">user-interface vty 0 4</span><br><span class="line">authentication-mode aaa</span><br><span class="line">protocol inbound ssh</span><br><span class="line">quit</span><br></pre></td></tr></table></figure>
<ul>
<li>创建SSH用户，并配置其认证方式为Password认证</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">aaa</span><br><span class="line">local-user client001 password cipher xxxxxx</span><br><span class="line">local-user client001 privilege level 3</span><br><span class="line">local-user client001 service-type ssh</span><br><span class="line">quit</span><br><span class="line">ssh user client001 authentication-type password</span><br></pre></td></tr></table></figure>
<ul>
<li>使能Stelnet服务器功能</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stelnet server enable</span><br></pre></td></tr></table></figure>
<ul>
<li>配置SSH用户服务方式为STelnet</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh user client001 service-type stelnet</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/03/16/华为S系列交换机配置SSH登录/" data-id="cj0bwhmkg00avwmpvdc44axaq" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Zabbix-监控-Windows-的-CPU-百分比" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/" class="article-date">
  <time datetime="2017-02-15T04:08:27.000Z" itemprop="datePublished">2017-02-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Zabbix/">Zabbix</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/">Zabbix 监控 Windows 的 CPU 百分比</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Zabbix 自带的模块没有 CPU 使用率（百分比）这个监控项，我们可以通过添加计数器的方式实现 CPU 百分比的监控。</p>
<p>在 Zabbix 的 WEB 端进行模板配置添加 CPU 百分比监控项目</p>
<p>*. 配置–模块–选择对应的模板–项目–创建项目</p>
<p>名称：CPU 百分比<br>键值：perf_counter[\Processor(_Total)\% Processor Time]<br>数据类型：数字的（浮点）<br>单位：%<br>数据更新间隔（秒）：30<br>应用集：CPU</p>
<p>*. 添加图形显示</p>
<p>*. 添加触发器CPU百分之85报警</p>
<p>表达式：{Windows 2008 R2:perf_counter[\Processor(_Total)\% Processor Time].avg(5m)}&gt;85</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/" data-id="cj0bwhmjt00a0wmpvv40sysvd" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Linux-访问-Windows-共享文件夹的两种方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/" class="article-date">
  <time datetime="2017-02-14T02:47:24.000Z" itemprop="datePublished">2017-02-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/">Linux 访问 Windows 共享文件夹的两种方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-mount-挂载"><a href="#1-mount-挂载" class="headerlink" title="1. mount 挂载"></a>1. mount 挂载</h2><p>首先创建被挂载的目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir windows</span><br></pre></td></tr></table></figure>
<p>将共享文件夹挂载到 windows 文件夹：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install cifs-utils  ## 安装必须组建</span><br><span class="line">mount.cifs //192.168.x.x/Backup ./windows -o user=backup  ## 挂载输入密码</span><br></pre></td></tr></table></figure>
<p>其中 /root/windows 表示挂载点，就是上面 windows 目录的完整路径。</p>
<h2 id="2-使用-samba-连接"><a href="#2-使用-samba-连接" class="headerlink" title="2. 使用 samba 连接"></a>2. 使用 samba 连接</h2><p>samba 就是让 windows 和 unix 系列 os 之间的文件可以互相访问的软件。使用 samba 访问 windows 的共享文件夹需要安装 smbclient。</p>
<p>安装好之后，就可以访问共享的文件了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbclient --user=backup //192.168.x.x/Backup/Backup  ## 输入密码</span><br></pre></td></tr></table></figure>
<p>此时进入 smb 的命令操作空间，可以使用 help 来查看命令的使用。</p>
<p>也可以使用 help 查看单个命令的使用方式。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/" data-id="cj0bwhmep0047wmpvxdivk1kt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-HTTP-请求" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/HTTP-请求/" class="article-date">
  <time datetime="2016-12-13T11:35:55.000Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/HTTP/">HTTP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/13/HTTP-请求/">HTTP 请求</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最常用请求：</p>
<ol>
<li>GET：请求获取由Request-URL所标识的资源</li>
<li>POST：在Request-URL所标识的资源后附加新的数据。例如：文件上传、提交表单</li>
</ol>
<p>都是为了实现服务器端的交互。用到的协议规则：</p>
<p>GET请求：</p>
<ol>
<li>第一行：方法 路径 协议版本（例如：GET / HTTP/1.1）</li>
<li>第二行：可以处理哪些类型的数据（例如：Accept: text/html, application/xhtml+xml, <em>/</em>）</li>
<li>第三行：可以接收的语言区域（例如：Accept-Language: zh-CN）</li>
<li>第四行：浏览器的客户端版本号</li>
<li>第五行：可以接收的编码格式（例如：Accept-Encoding: gzip, deflate）</li>
<li>第六行：表示访问的主机IP或者域名：Host</li>
<li>第七行：长连接（例如：Connection: Keep-Alive），由于每次传输都是建立TCP连接，消耗资源，所有有了长连接的机制，节省资源</li>
<li>第八行：Cookie（浏览器发送给服务器的内容）<br>。。。</li>
</ol>
<p>POST请求：</p>
<ol>
<li>第一行：方法 路径 协议版本（例如：POST / HTTP/1.1）</li>
<li>第二行：请求使用的方式（例如：x-requested-with: XMLHttpRequest）</li>
<li>第三行：可以接收的语言区域（例如：Accept-Language: zh-CN）</li>
<li>第四行：浏览器的请求来源，（例如：Referer: <a href="http://www.baidu.com/等）" target="_blank" rel="external">http://www.baidu.com/等）</a></li>
<li>第五行：Accept 可以处理哪些类型的数据<br>。。。</li>
</ol>
<p>响应：</p>
<ol>
<li>第一行：协议版本</li>
</ol>
<p>不常用请求：<br>HEAD OPTIONS PUT DELETE TRACE</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/12/13/HTTP-请求/" data-id="cj0bwhmba001jwmpv97iesfcz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-HTTP-协议基础" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/HTTP-协议基础/" class="article-date">
  <time datetime="2016-12-13T11:10:18.000Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/HTTP/">HTTP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/13/HTTP-协议基础/">HTTP 协议基础</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>HTTP作为应用层协议，更加关注的是内容本身，即需要传输的内容。</p>
<p><strong>特点：</strong></p>
<ol>
<li><p>明文传输，安全性差。</p>
</li>
<li><p>无状态协议。</p>
</li>
<li><p>应用层协议，标准化协议1.1版本。</p>
</li>
</ol>
<p>每个页面会对应一个或多个请求。</p>
<p><strong>主要构成：</strong></p>
<ol>
<li><p>请求</p>
</li>
<li><p>响应</p>
</li>
</ol>
<p>均包含协议头、协议正文。</p>
<p><strong>举例：</strong></p>
<ol>
<li><p>打电话：发起一个通话的请求</p>
</li>
<li><p>响应：通话成功 占线 停机 不接听 。。。</p>
</li>
</ol>
<p>200：标准的成功响应码<br>302：重定向<br>404：页面不存在<br>。。。</p>
<p>通常来说1、2、3开头的响应均表示请求是成功的，4开头的表示请求存在问题，5开头的表示服务端存在问题。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/12/13/HTTP-协议基础/" data-id="cj0bwhmb6001gwmpvnolleyqs" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-运行-Hadoop-伪分布式实例" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/29/运行-Hadoop-伪分布式实例/" class="article-date">
  <time datetime="2016-11-29T08:57:36.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/29/运行-Hadoop-伪分布式实例/">运行 Hadoop 伪分布式实例</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>伪分布式读取的是 HDFS 上的数据，要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 ~]# hdfs dfs -mkdir -p /user/root</span><br></pre></td></tr></table></figure>
<p>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/root/input 中。我们使用的是 root 用户，并且已创建相应的用户目录 /user/root，因此在此命令中就可以使用香断路径如 input，其对应的绝对路径就是 /user/root/input：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 ~]# hdfs dfs -mkdir input</span><br><span class="line">[root@slave3 ~]# hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>
<p>复制完成后，可以通过如下命令查看文件列表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 ~]# hdfs dfs -ls input</span><br><span class="line">Found 8 items</span><br><span class="line">-rw-r--r--   1 root supergroup       4436 2016-11-30 01:05 input/capacity-scheduler.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       1111 2016-11-30 01:05 input/core-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       9683 2016-11-30 01:05 input/hadoop-policy.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       1177 2016-11-30 01:05 input/hdfs-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup        620 2016-11-30 01:05 input/httpfs-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       3518 2016-11-30 01:05 input/kms-acls.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       5933 2016-11-30 01:05 input/kms-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup        690 2016-11-30 01:05 input/yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>伪分布式云新 MapReduce 作业的方式跟单击模式相同，区别在于伪分布式读取的是 HDFS 中的文件（可以将单机目录中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 hadoop]# hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure>
<p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 hadoop]# hdfs dfs -cat output/*</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br><span class="line">1	dfs.namenode.name.dir</span><br><span class="line">1	dfs.datanode.data.dir</span><br></pre></td></tr></table></figure>
<p>我们也可以将运行结果取回本地：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 hadoop]# rm -rf ./output   # 先删除本地的 output 文件夹（如果存在的话）</span><br><span class="line">[root@slave3 hadoop]# hdfs dfs -get output ./output   # 将 HDFS 上的 output 文件夹拷贝到本机</span><br><span class="line">[root@slave3 hadoop]# cat ./output/*</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br><span class="line">1	dfs.namenode.name.dir</span><br><span class="line">1	dfs.datanode.data.dir</span><br></pre></td></tr></table></figure>
<p>运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。</p>
<p>上述通过 start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们也可以启动 YARN，让 YARN 来负责资源管理与任务调度。这里需要修改 mapred-site.xml 和 yarn-site.xml 两个配置文件：</p>
<p>mapred-site.xml 配置文件修改如下：（mapred-site.xml是从mapred-site.template拷贝过来的）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">              &lt;name&gt;mapreduce.admin.user.env&lt;/name&gt;</span><br><span class="line">	      &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">              &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">              &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>yarn-site.xml 配置文件修改如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>然后就可以启动 YARN 了（当然需要先执行 start-dfs.sh）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br><span class="line">mapred --daemon start historyserver  #开启历史任务查看</span><br></pre></td></tr></table></figure>
<p>启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 <strong>mapred.LocalJobRunner</strong> 在跑任务，启用 YARN 之后，是 YARN 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况。</p>
<p>但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑的稍慢些。因此在单机上是否开启 YARN 就看实际情况了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/29/运行-Hadoop-伪分布式实例/" data-id="cj0bwhml900bzwmpvc8rkyr3t" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-安装教程-单机-伪分布式配置" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/29/Hadoop-安装教程-单机-伪分布式配置/" class="article-date">
  <time datetime="2016-11-29T07:35:26.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/29/Hadoop-安装教程-单机-伪分布式配置/">Hadoop 安装教程-单机/伪分布式配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 系统版本</span><br><span class="line">[root@slave3 hadoop]# cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.2.1511 (Core) </span><br><span class="line"></span><br><span class="line"># 本机IP：192.168.1.43</span><br><span class="line"></span><br><span class="line"># 本机HostName：slave3</span><br><span class="line"></span><br><span class="line"># 使用 yum -y update 更新系统</span><br></pre></td></tr></table></figure>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul>
<li><strong>主机名修改及Host修改</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname slave3</span><br><span class="line">vim /etc/hosts # 最后增加一行 192.168.1.43	slave3</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>安装常用软件及java</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install java-1.8.0-openjdk*</span><br><span class="line">yum install wget vim net-tools</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>确认java安装目录</strong></li>
</ul>
<p>通过 whereis java 以及 ls -l 的方式定位 java 安装目录，这里是<br>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64<br>具体可以参考：<a href="http://ttlop.com/2016/11/25/%E6%9F%A5%E6%89%BE%E9%80%9A%E8%BF%87Yum%E5%AE%89%E8%A3%85%E7%9A%84Java%E7%9A%84%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/">http://ttlop.com/2016/11/25/%E6%9F%A5%E6%89%BE%E9%80%9A%E8%BF%87Yum%E5%AE%89%E8%A3%85%E7%9A%84Java%E7%9A%84%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/</a></p>
<ul>
<li><strong>hadoop下载及配置</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget http://apache.fayea.com/hadoop/common/hadoop-3.0.0-alpha1/hadoop-3.0.0-alpha1.tar.gz</span><br><span class="line"># 解压</span><br><span class="line">tar zxvf hadoop-3.0.0-alpha1.tar.gz</span><br><span class="line"># 移动</span><br><span class="line">mv hadoop-3.0.0-alpha1 /usr/local/hadoop</span><br><span class="line"># 修改权限及确认</span><br><span class="line">cd /usr/local &amp;&amp; chown -R root.root hadoop &amp;&amp; ls -l hadoop &amp;&amp; cd hadoop &amp;&amp; ls -al</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>SSH 权限修改</strong></li>
</ul>
<p>通过ssh-keygen 及 authorized_keys 文件修改SSH登录权限。<br>具体可以参考：<a href="http://ttlop.com/2016/11/25/SSH-%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E8%8A%82%E7%82%B9/">http://ttlop.com/2016/11/25/SSH-%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E8%8A%82%E7%82%B9/</a></p>
<ul>
<li><strong>关闭防火墙即selinux</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 这里为测试环境，我们将安全选项都关闭</span><br><span class="line">setenforce 8</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>配置修改</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># PATH 修改（当前终端有效）</span><br><span class="line">export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin</span><br><span class="line"># hadoop 中 JAVA_HOME修改</span><br><span class="line">vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh</span><br><span class="line">增加  export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>单机配置测试</strong></li>
</ul>
<p>Hadoop 默认模式为非分布式模式，无需进行其它配置即可运行。非分布式即单 Java 进程，方便进行调试。<br>以下面为例，我们选择运行 grep 例子，我们将 input 文件夹中的所有文件作为输入，筛选当前符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">mkdir ./input</span><br><span class="line">cp ./etc/hadoop/*.xml ./input   # 将配置文件作为输入文件</span><br><span class="line">./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output &apos;dfs[a-z.]+&apos;</span><br><span class="line">cat ./output/*  # 查看运行结果</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>伪分布式配置</strong></li>
</ul>
<p>Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。</p>
<p>Hadoop 的配置文件位于 $HADOOP_HOME/etc/hadoop中，伪分布式需要修改2个配置文件 core-site.xml和hdfs-site.xml。Hadoop 的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。<br>如下是修改后的 core-site.xml文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/home/hadoop/tmp&lt;/value&gt;</span><br><span class="line">             &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<p>如下是修改后的 hdfs-site.xml文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/home/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/home/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<p>配置完成后，执行 NameNode 的格式化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>接着开启 NameNode 和 DataNode 守护进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 dfs]# jps</span><br><span class="line">50290 SecondaryNameNode</span><br><span class="line">50617 Jps</span><br><span class="line">50090 DataNode</span><br><span class="line">49995 NameNode</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/29/Hadoop-安装教程-单机-伪分布式配置/" data-id="cj0bwhmbv001xwmpvmvi9pt03" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Centos-7-LVM-磁盘扩容" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/29/Centos-7-LVM-磁盘扩容/" class="article-date">
  <time datetime="2016-11-29T05:55:06.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Centos-7/">Centos 7</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/29/Centos-7-LVM-磁盘扩容/">Centos 7 LVM 磁盘扩容</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hyper 主机有一台 Centos 7 虚拟机，系统是运行 Hadoop 环境，因为调试需要，准备扩容磁盘来增加空间。如何增加虚拟机磁盘空间的操作方法这里不作过多说明，都是图形化操作界面。</p>
<p>这里我们重点在介绍在 Centos 7中的操作。</p>
<ul>
<li><strong>查看现有的硬盘分区（现有空间没有变大）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# df -h</span><br><span class="line">文件系统                 容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root   50G  5.2G   45G   11% /</span><br><span class="line">devtmpfs                 1.9G     0  1.9G    0% /dev</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /dev/shm</span><br><span class="line">tmpfs                    1.9G  8.3M  1.9G    1% /run</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-home   73G   33M   73G    1% /home</span><br><span class="line">/dev/sda1                497M  152M  346M   31% /boot</span><br><span class="line">tmpfs                    379M     0  379M    0% /run/user/0</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>对新增加的硬盘空间做新增分区（硬盘数没有增加，增加的是空间）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# fdisk -l</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sda：818.2 GB, 818191269888 字节，1598029824 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x0009a639</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     1026047      512000   83  Linux</span><br><span class="line">/dev/sda2         1026048   266338303   132656128   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-swap：4177 MB, 4177526784 字节，8159232 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-root：53.7 GB, 53687091200 字节，104857600 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-home：78.0 GB, 77972111360 字节，152289280 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# fdisk /dev/sda</span><br><span class="line"></span><br><span class="line">The device presents a logical sector size that is smaller than</span><br><span class="line">the physical sector size. Aligning to a physical sector (or optimal</span><br><span class="line">I/O) size boundary is recommended, or performance may be impacted.</span><br><span class="line">欢迎使用 fdisk (util-linux 2.23.2)。</span><br><span class="line"></span><br><span class="line">更改将停留在内存中，直到您决定将更改写入磁盘。</span><br><span class="line">使用写入命令前请三思。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：n（说明：新增分区）</span><br><span class="line">Partition type:</span><br><span class="line">   p   primary (2 primary, 0 extended, 2 free)</span><br><span class="line">   e   extended</span><br><span class="line">Select (default p): p（说明：主分区）</span><br><span class="line">分区号 (3,4，默认 3)：（说明：新增分区号（1，2默认已经使用））</span><br><span class="line">起始 扇区 (266338304-1598029823，默认为 266338304)：（说明：默认回车最小）</span><br><span class="line">将使用默认值 266338304</span><br><span class="line">Last 扇区, +扇区 or +size&#123;K,M,G&#125; (266338304-1598029823，默认为 1598029823)：（说明：默认回车最大）</span><br><span class="line">将使用默认值 1598029823</span><br><span class="line">分区 3 已设置为 Linux 类型，大小设为 635 GiB</span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：t（说明：修改分区类型）</span><br><span class="line">分区号 (1-3，默认 3)：3（说明：修改分区类型对应的分区号）</span><br><span class="line">Hex 代码(输入 L 列出所有代码)：8e（说明：8e是lvm磁盘类型）</span><br><span class="line">已将分区“Linux”的类型更改为“Linux LVM”</span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：p（说明：打印分区表）</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sda：818.2 GB, 818191269888 字节，1598029824 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x0009a639</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     1026047      512000   83  Linux</span><br><span class="line">/dev/sda2         1026048   266338303   132656128   8e  Linux LVM</span><br><span class="line">/dev/sda3       266338304  1598029823   665845760   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：w（说明：保存退出）</span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line"></span><br><span class="line">WARNING: Re-reading the partition table failed with error 16: 设备或资源忙.</span><br><span class="line">The kernel still uses the old table. The new table will be used at</span><br><span class="line">the next reboot or after you run partprobe(8) or kpartx(8)</span><br><span class="line">正在同步磁盘。</span><br><span class="line">[root@slave2 ~]#</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>重启系统</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# reboot</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查看硬盘情况（核对刚才所做的分区操作是否保存成功）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# fdisk -l</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sda：818.2 GB, 818191269888 字节，1598029824 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x0009a639</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     1026047      512000   83  Linux</span><br><span class="line">/dev/sda2         1026048   266338303   132656128   8e  Linux LVM</span><br><span class="line">/dev/sda3       266338304  1598029823   665845760   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-swap：4177 MB, 4177526784 字节，8159232 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-root：53.7 GB, 53687091200 字节，104857600 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-home：78.0 GB, 77972111360 字节，152289280 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查看当前分区类型</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# df -T /dev/sda1</span><br><span class="line">文件系统       类型  1K-块   已用   可用 已用% 挂载点</span><br><span class="line">/dev/sda1      xfs  508588 154808 353780   31% /boot</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>创建文件系统在新的磁盘上</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# mkfs.xfs /dev/sda3</span><br><span class="line">meta-data=/dev/sda3              isize=256    agcount=4, agsize=41615360 blks</span><br><span class="line">         =                       sectsz=4096  attr=2, projid32bit=1</span><br><span class="line">         =                       crc=0        finobt=0</span><br><span class="line">data     =                       bsize=4096   blocks=166461440, imaxpct=25</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=0</span><br><span class="line">log      =internal log           bsize=4096   blocks=81280, version=2</span><br><span class="line">         =                       sectsz=4096  sunit=1 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>创建pv、查看pv状态（PV组成VG，VG组成LV）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda2</span><br><span class="line">  VG Name               centos</span><br><span class="line">  PV Size               126.51 GiB / not usable 3.00 MiB</span><br><span class="line">  Allocatable           yes (but full)</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              32386</span><br><span class="line">  Free PE               0</span><br><span class="line">  Allocated PE          32386</span><br><span class="line">  PV UUID               ddZZPI-6Wty-4qgS-RPMY-Gdsd-jih4-cqP0vQ</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# pvcreate /dev/sda3</span><br><span class="line">  Device /dev/sda3 not found (or ignored by filtering).</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda2</span><br><span class="line">  VG Name               centos</span><br><span class="line">  PV Size               126.51 GiB / not usable 3.00 MiB</span><br><span class="line">  Allocatable           yes (but full)</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              32386</span><br><span class="line">  Free PE               0</span><br><span class="line">  Allocated PE          32386</span><br><span class="line">  PV UUID               ddZZPI-6Wty-4qgS-RPMY-Gdsd-jih4-cqP0vQ</span><br><span class="line">   </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda3</span><br><span class="line">  VG Name               centos</span><br><span class="line">  PV Size               635.00 GiB / not usable 4.00 MiB</span><br><span class="line">  Allocatable           yes </span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              162559</span><br><span class="line">  Free PE               162559</span><br><span class="line">  Allocated PE          0</span><br><span class="line">  PV UUID               OiezFh-mTSY-u0Xk-pADo-rJsc-dfT5-kfCUCF</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>刚创建的PV加入相应的VG</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# vgextend centos /dev/sda3</span><br><span class="line">WARNING: xfs signature detected on /dev/sda3 at offset 0. Wipe it? [y/n]: y</span><br><span class="line">  Wiping xfs signature on /dev/sda3.</span><br><span class="line">  Physical volume &quot;/dev/sda3&quot; successfully created</span><br><span class="line">  Volume group &quot;centos&quot; successfully extended</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查看LV状态，把VG加入到LV</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# lvdisplay </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/centos/swap</span><br><span class="line">  LV Name                swap</span><br><span class="line">  VG Name                centos</span><br><span class="line">  LV UUID                x2Acgw-2v1S-HrpP-rJCW-b259-RivD-qF6fdC</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time bogon, 2016-11-23 10:32:37 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  # open                 2</span><br><span class="line">  LV Size                3.89 GiB</span><br><span class="line">  Current LE             996</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:0</span><br><span class="line">   </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/centos/home</span><br><span class="line">  LV Name                home</span><br><span class="line">  VG Name                centos</span><br><span class="line">  LV UUID                lbxRvi-O3Th-EAdc-2dKL-Pf13-YvQn-Om88WI</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time bogon, 2016-11-23 10:32:37 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  # open                 1</span><br><span class="line">  LV Size                72.62 GiB</span><br><span class="line">  Current LE             18590</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:2</span><br><span class="line">   </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/centos/root</span><br><span class="line">  LV Name                root</span><br><span class="line">  VG Name                centos</span><br><span class="line">  LV UUID                oqgktg-XpOf-2HXX-rrLM-pGW0-ebs0-e2FR8j</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time bogon, 2016-11-23 10:32:39 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  # open                 1</span><br><span class="line">  LV Size                50.00 GiB</span><br><span class="line">  Current LE             12800</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:1</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# lvextend -l +162559 /dev/mapper/centos-home </span><br><span class="line">  Size of logical volume centos/home changed from 72.62 GiB (18590 extents) to 707.61 GiB (181149 extents).</span><br><span class="line">  Logical volume home successfully resized.</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>调整文件系统大小</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# xfs_growfs /dev/mapper/centos-home </span><br><span class="line">meta-data=/dev/mapper/centos-home isize=256    agcount=4, agsize=4759040 blks</span><br><span class="line">         =                       sectsz=512   attr=2, projid32bit=1</span><br><span class="line">         =                       crc=0        finobt=0</span><br><span class="line">data     =                       bsize=4096   blocks=19036160, imaxpct=25</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=0</span><br><span class="line">log      =internal               bsize=4096   blocks=9295, version=2</span><br><span class="line">         =                       sectsz=512   sunit=0 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br><span class="line">data blocks changed from 19036160 to 185496576</span><br><span class="line">[root@slave2 ~]# df -h</span><br><span class="line">文件系统                 容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root   50G  5.2G   45G   11% /</span><br><span class="line">devtmpfs                 1.9G     0  1.9G    0% /dev</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /dev/shm</span><br><span class="line">tmpfs                    1.9G  8.3M  1.9G    1% /run</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-home  708G   34M  708G    1% /home</span><br><span class="line">/dev/sda1                497M  152M  346M   31% /boot</span><br><span class="line">tmpfs                    379M     0  379M    0% /run/user/0</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/29/Centos-7-LVM-磁盘扩容/" data-id="cj0bwhm9s000owmpvtj3dq5vg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-Yarn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-Yarn/" class="article-date">
  <time datetime="2016-11-26T08:14:13.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-Yarn/">Hadoop Yarn</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Yarn-简介"><a href="#Yarn-简介" class="headerlink" title="Yarn 简介"></a>Yarn 简介</h1><p>YARN的基本思想是将 JobTracker 的两个主要功能（资源管理和作业调度/监控）分离，主要方法是创建一个全局的ResourceManager（RM）和若干个针对应用程序的ApplicationMaster（AM）。这里的应用程序是指传统的MapReduce作业或作业的DAG（有向无环图）。</p>
<p>YARN 分层结构的本质是 ResourceManager。这个实体控制整个集群并管理应用程序向基础计算资源的分配。ResourceManager 将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）。ResourceManager 还与 ApplicationMaster 一起分配资源，与 NodeManager 一起启动和监视它们的基础应用程序。在此上下文中，ApplicationMaster 承担了以前的 TaskTracker 的一些角色，ResourceManager 承担了 JobTracker 的角色。<br>ApplicationMaster 管理一个在 YARN 内运行的应用程序的每个实例。ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）。请注意，尽管目前的资源更加传统（CPU 核心、内存），但未来会带来基于手头任务的新资源类型（比如图形处理单元或专用处理设备）。从 YARN 角度讲，ApplicationMaster 是用户代码，因此存在潜在的安全问题。YARN 假设 ApplicationMaster 存在错误或者甚至是恶意的，因此将它们当作无特权的代码对待。<br>NodeManager 管理一个 YARN 集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。MRv1 通过插槽管理 Map 和 Reduce 任务的执行，而 NodeManager 管理抽象容器，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源。YARN 继续使用 HDFS 层。它的主要 NameNode 用于元数据服务，而 DataNode 用于分散在一个集群中的复制存储服务。<br>要使用一个 YARN 集群，首先需要来自包含一个应用程序的客户的请求。ResourceManager 协商一个容器的必要资源，启动一个 ApplicationMaster 来表示已提交的应用程序。通过使用一个资源请求协议，ApplicationMaster 协商每个节点上供应用程序使用的资源容器。执行应用程序时，ApplicationMaster 监视容器直到完成。当应用程序完成时，ApplicationMaster 从 ResourceManager 注销其容器，执行周期就完成了。</p>
<h2 id="MRv1-的缺陷"><a href="#MRv1-的缺陷" class="headerlink" title="MRv1 的缺陷"></a>MRv1 的缺陷</h2><p>MapReduce 的第一个版本既有优点也有缺点。MRv1 是目前使用的标准的大数据处理系统。但是，这种架构存在不足，主要表现在大型集群上。当集群包含的节点超过 4,000 个时（其中每个节点可能是多核的），就会表现出一定的不可预测性。其中一个最大的问题是级联故障，由于要尝试复制数据和重载活动的节点，所以一个故障会通过网络泛洪形式导致整个集群严重恶化。<br>但 MRv1 的最大问题是多租户。随着集群规模的增加，一种可取的方式是为这些集群采用各种不同的模型。MRv1 的节点专用于 Hadoop，所以可以改变它们的用途以用于其他应用程序和工作负载。当大数据和 Hadoop 成为云部署中一个更重要的使用模型时，这种能力也会增强，因为它允许在服务器上对 Hadoop 进行物理化，而无需虚拟化且不会增加管理、计算和输入/输出开销。</p>
<h2 id="Yarn的优点"><a href="#Yarn的优点" class="headerlink" title="Yarn的优点"></a>Yarn的优点</h2><p>大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。<br>在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。<br>对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。<br>老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的运行状况，如果出问题，会将其在其他机器上重启。<br>Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>
<h2 id="YARN的核心思想"><a href="#YARN的核心思想" class="headerlink" title="YARN的核心思想"></a>YARN的核心思想</h2><p>将JobTracker和TaskTacker进行分离，它由下面几大构成组件：<br>a. 一个全局的资源管理器 ResourceManager<br>b. ResourceManager的每个节点代理 NodeManager<br>c. 表示每个应用的 ApplicationMaster<br>d. 每一个ApplicationMaster拥有多个Container在NodeManager上运行[2]  </p>
<h1 id="YARN的主要架构"><a href="#YARN的主要架构" class="headerlink" title="YARN的主要架构"></a>YARN的主要架构</h1><h2 id="ResourceManager（RM）"><a href="#ResourceManager（RM）" class="headerlink" title="ResourceManager（RM）"></a>ResourceManager（RM）</h2><p>RM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，ASM）。<br>调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。<br>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。</p>
<h2 id="ApplicationMaster（AM）"><a href="#ApplicationMaster（AM）" class="headerlink" title="ApplicationMaster（AM）"></a>ApplicationMaster（AM）</h2><p>用户提交的每个应用程序均包含一个AM，主要功能包括：<br>与RM调度器协商以获取资源（用Container表示）；<br>将得到的任务进一步分配给内部的任务(资源的二次分配)；<br>与NM通信以启动/停止任务；<br>监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。<br>当前YARN自带了两个AM实现，一个是用于演示AM编写方法的实例程序distributedshell，它可以申请一定数目的Container以并行运行一个Shell命令或者Shell脚本；另一个是运行MapReduce应用程序的AM—MRAppMaster。<br>注：RM只负责监控AM，在AM运行失败时候启动它，RM并不负责AM内部任务的容错，这由AM来完成。</p>
<h2 id="NodeManager（NM）"><a href="#NodeManager（NM）" class="headerlink" title="NodeManager（NM）"></a>NodeManager（NM）</h2><p>NM是每个节点上的资源和任务管理器，一方面，它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，它接收并处理来自AM的Container启动/停止等各种请求</p>
<h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h2><p>Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container表示。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。<br>注：1. Container不同于MRv1中的slot，它是一个动态资源划分单位，是根据应用程序的需求动态生成的。</p>
<ol>
<li>现在YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。<br>YARN的资源管理和执行框架都是按主/从范例实现的——Slave —节点管理器（NM）运行、监控每个节点，并向集群的Master—资源管理器(RM)报告资源的可用性状态，资源管理器最终为系统里所有应用分配资源。<br>特定应用的执行由ApplicationMaster控制，ApplicationMaster负责将一个应用分割成多个任务，并和资源管理器协调执行所需的资源，资源一旦分配好，ApplicationMaster就和节点管理器一起安排、执行、监控独立的应用任务。<br>需要说明的是， YARN不同服务组件的通信方式采用了事件驱动的异步并发机制，这样可以简化系统的设计。</li>
</ol>
<h1 id="YARN架构简析"><a href="#YARN架构简析" class="headerlink" title="YARN架构简析"></a>YARN架构简析</h1><h2 id="集中式架构"><a href="#集中式架构" class="headerlink" title="集中式架构"></a>集中式架构</h2><p>集中式调度器(Monolithic Scheduler)的特点是，资源的调度和应用程序的管理功能全部放到一个进程中完成，开源界典型的代表是MRv1 JobTracker的实现。这样设计的缺点很明显，扩展性差：首先，集群规模受限；其次，新的调度策略难以融入到现有代码中，比如之前仅支持MapReduce作业，现在要支持流式作业，而将流式作业的调度策略嵌入到中央调度其中是一项很难的工作。</p>
<h2 id="双层调度架构"><a href="#双层调度架构" class="headerlink" title="双层调度架构"></a>双层调度架构</h2><p>为了克服集中式调度器的不足，双层调度器是一种很容易被想到的解决之道，它可看作是一种分而治之的机制或者是策略下放机制：双层调度器仍保留一个经简化的集中式资源调度器，但具体任务相关的调度策略则下放到各个应用程序调度器完成。这种调度器的典型代表是Mesos。Mesos调度器由两部分组成，分别是资源调度器和框架(应用程序)调度器,其中，资源调度器负责将集群中的资源分配给各个框架(应用程序),而框架(应用程序)调度器负责将资源进一步分配给内部的各个任务，用户很容易将一种框架或者系统接入Mesos.<br>双层调度器的特点是：各个框架调度器并不知道整个集群资源使用情况，只是被动地接受资源；资源调度器仅将可用的资源推送给各个框架，而由框架自己选择是使用还是拒绝这些资源；一旦框架接受到新资源，再进一步将资源分配给其内部的任务，进而实现双层调度。然而这种调度器也是有缺点，主要表现在以下两个方面:1.各个框架无法知道整个集群的实时资源使用情况；采用悲观锁，并发粒度小。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-Yarn/" data-id="cj0bwhmbn001twmpvlj5kufgo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-新-MapReduce-框架-Yarn-详解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/" class="article-date">
  <time datetime="2016-11-26T06:33:17.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/">Hadoop 新 MapReduce 框架 Yarn 详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Hadoop-MapReduceV2-Yarn-框架简介"><a href="#Hadoop-MapReduceV2-Yarn-框架简介" class="headerlink" title="Hadoop MapReduceV2(Yarn) 框架简介"></a>Hadoop MapReduceV2(Yarn) 框架简介</h2><h3 id="原-Hadoop-MapReduce-框架的问题"><a href="#原-Hadoop-MapReduce-框架的问题" class="headerlink" title="原 Hadoop MapReduce 框架的问题"></a>原 Hadoop MapReduce 框架的问题</h3><p><strong>图1：Hadoop 原 MapReduce 架构</strong><br><img src="/myimages/image001.jpg" alt="Hadoop 原 MapReduce 架构"><br>从上图中可以清楚的看出原 MapReduce 程序的流程及设计思路：</p>
<ol>
<li>首先用户程序（JobClient）提交了一个job，job的信息会发送到JobTracker，JobTracker是Map-reduce框架的中心，它需要与集群中的机器定时通信（heartbeat），需要管理哪些程序应该跑在哪些机器上，需要管理所有job失败、重启等操作。</li>
<li>TaskTracker 是 Map-reduce 集群中每台机器都有的一个部分，它做的事情是监视自己所在机器的资源情况。</li>
<li>TaskTracker 同时监视当前机器的tasks运行情况，TaskTracker需要把这些信息通过heartbeat发送给JobTracker，JobTracker会收集这些信息以给新提交的job分配运行在哪些机器上。上图虚线就是标识消息的发送-接收的过程。<br>可以看得出原来的 map-reduce 架构是简单明了的，在最初推出的几年，也得到了众多的成功案例，获得业界广泛的支持和肯定，但随着分布式系统集群的规模和其工作负荷的增长，原框架的问题逐渐浮出水面，主要的问题集中如下：</li>
<li>JobTracker 是 Map-reduce 的集中处理点，存在单点故障。<br>JobTracker 完成了太多的任务，造成了过多的资源消耗，当 map-reduce job 非常多的时候，会造成很大的内存开销，潜在来说，也增加了 JobTracker fail 的风险，这也是业界普遍总结出老 Hadoop 的 Map-Reduce 只能支持 4000 节点主机的上限。</li>
<li>在 TaskTracker 端，以 map/reduce task 的数目作为资源的表示过于简单，没有考虑到 cpu/ 内存的占用情况，如果两个大内存消耗的 task 被调度到了一块，很容易出现 OOM。</li>
<li>在 TaskTracker 端，把资源强制划分为 map task slot 和 reduce task slot, 如果当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费，也就是前面提过的集群资源利用的问题。4. 源代码层面分析的时候，会发现代码非常的难读，常常因为一个 class 做了太多的事情，代码量达 3000 多行，造成 class 的任务不清晰，增加 bug 修复和版本维护的难度。</li>
<li>从操作的角度来看，现在的 Hadoop MapReduce 框架在有任何重要的或者不重要的变化 ( 例如 bug 修复，性能提升和特性化 ) 时，都会强制进行系统级别的升级更新。更糟的是，它不管用户的喜好，强制让分布式集群系统的每一个用户端同时更新。这些更新会让用户为了验证他们之前的应用程序是不是适用新的 Hadoop 版本而浪费大量时间。</li>
</ol>
<h3 id="新-Hadoop-Yarn-框架原理及运作机制"><a href="#新-Hadoop-Yarn-框架原理及运作机制" class="headerlink" title="新 Hadoop Yarn 框架原理及运作机制"></a>新 Hadoop Yarn 框架原理及运作机制</h3><p>从业界使用分布式系统的变化趋势和 hadoop 框架的长远发展来看，MapReduce 的 JobTracker/TaskTracker 机制需要大规模的调整来修复它在可扩展性，内存消耗，线程模型，可靠性和性能上的缺陷。在过去的几年中，hadoop 开发团队做了一些 bug 的修复，但是最近这些修复的成本越来越高，这表明对原框架做出改变的难度越来越大。</p>
<p>为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：</p>
<p><strong>图2：新的 Hadoop MapReduce 框架（Yarn）架构</strong><br><img src="/myimages/image002.jpg" alt="新的 Hadoop MapReduce 框架（Yarn）架构"></p>
<p>重构根本的思想是将 JobTracker 两个主要的功能分离成单独的组件，这两个功能是资源管理和任务调度 / 监控。新的资源管理器全局管理所有应用程序计算资源的分配，每一个应用的 ApplicationMaster 负责相应的调度和协调。一个应用程序无非是一个单独的传统的 MapReduce 任务或者是一个 DAG( 有向无环图 ) 任务。ResourceManager 和每一台机器的节点管理服务器能够管理用户在那台机器上的进程并能对计算进行组织。</p>
<p>事实上，每一个应用的 ApplicationMaster 是一个详细的框架库，它结合从 ResourceManager 获得的资源和 NodeManager 协同工作来运行和监控任务。</p>
<p>上图中 ResourceManager 支持分层级的应用队列，这些队列享有集群一定比例的资源。从某种意义上讲它就是一个纯粹的调度器，它在执行过程中不对应用进行监控和状态跟踪。同样，它也不能重启因应用失败或者硬件错误而运行失败的任务。</p>
<p>ResourceManager 是基于应用程序对资源的需求进行调度的 ; 每一个应用程序需要不同类型的资源因此就需要不同的容器。资源包括：内存，CPU，磁盘，网络等等。可以看出，这同现 Mapreduce 固定类型的资源使用模型有显著区别，它给集群的使用带来负面的影响。资源管理器提供一个调度策略的插件，它负责将集群资源分配给多个队列和应用程序。调度插件可以基于现有的能力调度和公平调度模型。</p>
<p>上图中 NodeManager 是每一台机器框架的代理，是执行应用程序的容器，监控应用程序的资源使用情况 (CPU，内存，硬盘，网络 ) 并且向调度器汇报。</p>
<p>每一个应用的 ApplicationMaster 的职责有：向调度器索要适当的资源容器，运行任务，跟踪应用程序的状态和监控它们的进程，处理任务的失败原因。</p>
<h3 id="新旧-Hadoop-MapReduce-框架比对"><a href="#新旧-Hadoop-MapReduce-框架比对" class="headerlink" title="新旧 Hadoop MapReduce 框架比对"></a>新旧 Hadoop MapReduce 框架比对</h3><p>让我们来对新旧 MapReduce 框架做详细的分析和对比，可以看到有以下几点显著变化：</p>
<p>首先客户端不变，其调用 API 及接口大部分保持兼容，这也是为了对开发使用者透明化，使其不必对原有代码做大的改变，但是原框架中核心的 JobTracker 和 TaskTracker 不见了，取而代之的是 ResourceManager, ApplicationMaster 与 NodeManager 三个部分。</p>
<p>我们来详细解释这三个部分，首先 ResourceManager 是一个中心的服务，它做的事情是调度、启动每一个 Job 所属的 ApplicationMaster、另外监控 ApplicationMaster 的存在情况。细心的读者会发现：Job 里面所在的 task 的监控、重启等等内容不见了。这就是 AppMst 存在的原因。ResourceManager 负责作业与资源的调度。接收 JobSubmitter 提交的作业，按照作业的上下文 (Context) 信息，以及从 NodeManager 收集来的状态信息，启动调度过程，分配一个 Container 作为 App Mstr</p>
<p>NodeManager 功能比较专一，就是负责 Container 状态的维护，并向 RM 保持心跳。</p>
<p>ApplicationMaster 负责一个 Job 生命周期内的所有工作，类似老的框架中 JobTracker。但注意每一个 Job（不是每一种）都有一个 ApplicationMaster，它可以运行在 ResourceManager 以外的机器上。</p>
<p>Yarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：</p>
<p>这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。<br>在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。<br>对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。<br>老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的运行状况，如果出问题，会将其在其他机器上重启。<br>Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>
<p>新的 Yarn 框架相对旧 MapRduce 框架而言，其配置文件 , 启停脚本及全局变量等也发生了一些变化，主要的改变如下：</p>
<p><strong>表1：新旧 Hadoop 脚本 / 变量 / 位置变化表</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">改变项</th>
<th style="text-align:left">原框架中</th>
<th style="text-align:left">新框架中（Yarm）</th>
<th style="text-align:left">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">配置文件位置</td>
<td style="text-align:left">${hadoop_home_dir}/conf</td>
<td style="text-align:left">${hadoop_home_dir}/etc/hadoop</td>
<td style="text-align:left">Yarn 框架也兼容老的 ${hadoop_home_dir}/conf 位置配置，启动时会检测是否存在老的 conf 目录，如果存在将加载 conf 目录下的配置，否则加载 etc 下配置</td>
</tr>
<tr>
<td style="text-align:left">启停脚本</td>
<td style="text-align:left">${hadoop_home_dir}/bin/start（stop）-all.sh</td>
<td style="text-align:left">${hadoop_home_dir}/sbin/start（stop）-dfs.sh ${hadoop_home_dir}/bin/start(stop)-all.sh</td>
<td style="text-align:left">新的 Yarn 框架中启动分布式文件系统和启动 Yarn 分离，启动 / 停止分布式文件系统的命令位于 ${hadoop_home_dir}/sbin 目录下，启动 / 停止 Yarn 框架位于 ${hadoop_home_dir}/bin/ 目录下</td>
</tr>
<tr>
<td style="text-align:left">JAVA_HOME 全局变量</td>
<td style="text-align:left">${hadoop_home_dir}/bin/start-all.sh 中</td>
<td style="text-align:left">${hadoop_home_dir}/etc/hadoop/hadoop-env.sh ${hadoop_home_dir}/etc/hadoop/Yarn-env.sh</td>
<td style="text-align:left">Yarn 框架中由于启动 hdfs 分布式文件系统和启动 MapReduce 框架分离，JAVA_HOME 需要在 hadoop-env.sh 和 Yarn-env.sh 中分别配置</td>
</tr>
<tr>
<td style="text-align:left">HADOOP_LOG_DIR 全局变量</td>
<td style="text-align:left">不需要配置</td>
<td style="text-align:left">${hadoop_home_dir}/etc/hadoop/hadoop-env.sh</td>
<td style="text-align:left">老框架在 LOG，conf，tmp 目录等均默认为脚本启动的当前目录下的 log,conf，tmp 子目录，Yarn 新框架中 Log 默认创建在 Hadoop 用户的 home 目录下的 log 子目录，因此最好在 ${hadoop_home_dir}/etc/hadoop/hadoop-env.sh 配置 HADOOP_LOG_DIR，否则有可能会因为你启动 hadoop 的用户的 .bashrc 或者 .bash_profile 中指定了其他的 PATH 变量而造成日志位置混乱，而该位置没有访问权限的话启动过程中会报错</td>
</tr>
</tbody>
</table>
<p>由于新的 Yarn 框架与原 Hadoop MapReduce 框架相比变化较大，核心的配置文件中很多项在新框架中已经废弃，而新框架中新增了很多其他配置项，看下表所示会更加清晰：</p>
<p><strong>表2:新旧 Hadoop 框架配置项变化表</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">配置文件</th>
<th style="text-align:left">配置项</th>
<th style="text-align:left">Hadoop 0.20.X配置</th>
<th style="text-align:left">Hadoop 0.23.X配置</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">core-site.xml</td>
<td style="text-align:left">系统默认分布式文件URL</td>
<td style="text-align:left">fs.default.name</td>
<td style="text-align:left">fs.defaultFS</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">hdfs-site.xml</td>
<td style="text-align:left">DFS name node 存放 name table 的目录</td>
<td style="text-align:left">dfs.name.dir</td>
<td style="text-align:left">dfs.namenode.name.dir</td>
<td style="text-align:left">新框架中 name node 分成 dfs.namenode.name.dir( 存放 naname table 和 dfs.namenode.edits.dir（存放 edit 文件），默认是同一个目录</td>
</tr>
<tr>
<td style="text-align:left">hdfs-site.xml</td>
<td style="text-align:left">DFS data node 存放数据block的目录</td>
<td style="text-align:left">dfs.data.dir</td>
<td style="text-align:left">dfs.datanode.data.dir</td>
<td style="text-align:left">新框架中 DataNode 增加更多细节配置，位于 dfs.datanode. 配置项下，如 dfs.datanode.data.dir.perm（datanode local 目录默认权限）；dfs.datanode.address（datanode 节点监听端口）；等</td>
</tr>
<tr>
<td style="text-align:left">hdfs-site.xml</td>
<td style="text-align:left">分布式文件系统数据复制块</td>
<td style="text-align:left">dfs.replication</td>
<td style="text-align:left">dfs.replication</td>
<td style="text-align:left">新框架与老框架一致，值建议配置为与分布式 cluster 中实际的 DataNode 主机数一致</td>
</tr>
<tr>
<td style="text-align:left">mapred-site.xml</td>
<td style="text-align:left">Job监控地址及端口</td>
<td style="text-align:left">mapred.job.tracker</td>
<td style="text-align:left">无</td>
<td style="text-align:left">新框架中已改为 Yarn-site.xml 中的 resouceManager 及 nodeManager 具体配置项，新框架中历史 job 的查询已从 Job tracker 剥离，归入单独的 mapreduce.jobtracker.jobhistory 相关配置，</td>
</tr>
<tr>
<td style="text-align:left">mapred-site.xml</td>
<td style="text-align:left">第三方MapReduce框架</td>
<td style="text-align:left">无</td>
<td style="text-align:left">mapreduce.framework.name</td>
<td style="text-align:left">新框架支持第三方 MapReduce 开发框架以支持如 SmartTalk/DGSG 等非 Yarn 架构，注意通常情况下这个配置的值都设置为 Yarn，如果没有配置这项，那么提交的 Yarn job 只会运行在 locale 模式，而不是分布式模式。</td>
</tr>
<tr>
<td style="text-align:left">yarn-site.xml</td>
<td style="text-align:left">The address of the applications manager interface in the RM</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.address</td>
<td style="text-align:left">新框架中 NodeManager 与 RM 通信的接口地址</td>
</tr>
<tr>
<td style="text-align:left">yarn-site.xml</td>
<td style="text-align:left">The address of the scheduler interface</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.scheduler.address</td>
<td style="text-align:left">同上，NodeManger 需要知道 RM 主机的 scheduler 调度服务接口地址</td>
</tr>
<tr>
<td style="text-align:left">yarn-site.xml</td>
<td style="text-align:left">The address of the RM web application</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.webapp.address</td>
<td style="text-align:left">新框架中各个 task 的资源调度及运行状况通过通过该 web 界面访问</td>
</tr>
<tr>
<td style="text-align:left">yarn-site.xml</td>
<td style="text-align:left">The address of the resource tracker interface</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.resource-tracker.address</td>
<td style="text-align:left">新框架中 NodeManager 需要向 RM 报告任务运行状态供 Resouce 跟踪，因此 NodeManager 节点主机需要知道 RM 主机的 tracker 接口地址</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/" data-id="cj0bwhmc20021wmpvblsykneh" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Apache/">Apache</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Bat/">Bat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Centos-7/">Centos 7</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTTP/">HTTP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HUAWEI/">HUAWEI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hyper-V/">Hyper-V</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Iptables/">Iptables</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MikroTik/">MikroTik</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mysql/">Mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nagios/">Nagios</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx/">Nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Postfix/">Postfix</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis/">Redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/03/16/华为S系列交换机配置SSH登录/">华为S系列交换机配置SSH登录</a>
          </li>
        
          <li>
            <a href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/">Zabbix 监控 Windows 的 CPU 百分比</a>
          </li>
        
          <li>
            <a href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/">Linux 访问 Windows 共享文件夹的两种方法</a>
          </li>
        
          <li>
            <a href="/2016/12/13/HTTP-请求/">HTTP 请求</a>
          </li>
        
          <li>
            <a href="/2016/12/13/HTTP-协议基础/">HTTP 协议基础</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 XiaoYong Hu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/About" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>