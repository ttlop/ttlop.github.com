<!DOCTYPE html>
<html>

<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?639ab28f32e0029ed25324113f0ff34a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


<head>
  <meta charset="utf-8">
  
  <title>运维生存时间</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="运维 生存时间 ttl op oa">
<meta property="og:type" content="website">
<meta property="og:title" content="运维生存时间">
<meta property="og:url" content="http://ttlop.com/index.html">
<meta property="og:site_name" content="运维生存时间">
<meta property="og:description" content="运维 生存时间 ttl op oa">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="运维生存时间">
<meta name="twitter:description" content="运维 生存时间 ttl op oa">
  
    <link rel="alternate" href="/atom.xml" title="运维生存时间" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">运维生存时间</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">业精于勤而荒于嬉，行成于思而毁于随</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/About">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://ttlop.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Hadoop-新-MapReduce-框架-Yarn-详解" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/" class="article-date">
  <time datetime="2016-11-26T06:33:17.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/">Hadoop 新 MapReduce 框架 Yarn 详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Hadoop-MapReduceV2-Yarn-框架简介"><a href="#Hadoop-MapReduceV2-Yarn-框架简介" class="headerlink" title="Hadoop MapReduceV2(Yarn) 框架简介"></a>Hadoop MapReduceV2(Yarn) 框架简介</h2><h3 id="原-Hadoop-MapReduce-框架的问题"><a href="#原-Hadoop-MapReduce-框架的问题" class="headerlink" title="原 Hadoop MapReduce 框架的问题"></a>原 Hadoop MapReduce 框架的问题</h3><p><strong>图1：Hadoop 原 MapReduce 架构</strong><br><img src="/myimages/image001.jpg" alt="Hadoop 原 MapReduce 架构"><br>从上图中可以清楚的看出原 MapReduce 程序的流程及设计思路：</p>
<ol>
<li>首先用户程序（JobClient）提交了一个job，job的信息会发送到JobTracker，JobTracker是Map-reduce框架的中心，它需要与集群中的机器定时通信（heartbeat），需要管理哪些程序应该跑在哪些机器上，需要管理所有job失败、重启等操作。</li>
<li>TaskTracker 是 Map-reduce 集群中每台机器都有的一个部分，它做的事情是监视自己所在机器的资源情况。</li>
<li>TaskTracker 同时监视当前机器的tasks运行情况，TaskTracker需要把这些信息通过heartbeat发送给JobTracker，JobTracker会收集这些信息以给新提交的job分配运行在哪些机器上。上图虚线就是标识消息的发送-接收的过程。<br>可以看得出原来的 map-reduce 架构是简单明了的，在最初推出的几年，也得到了众多的成功案例，获得业界广泛的支持和肯定，但随着分布式系统集群的规模和其工作负荷的增长，原框架的问题逐渐浮出水面，主要的问题集中如下：</li>
<li>JobTracker 是 Map-reduce 的集中处理点，存在单点故障。<br>JobTracker 完成了太多的任务，造成了过多的资源消耗，当 map-reduce job 非常多的时候，会造成很大的内存开销，潜在来说，也增加了 JobTracker fail 的风险，这也是业界普遍总结出老 Hadoop 的 Map-Reduce 只能支持 4000 节点主机的上限。</li>
<li>在 TaskTracker 端，以 map/reduce task 的数目作为资源的表示过于简单，没有考虑到 cpu/ 内存的占用情况，如果两个大内存消耗的 task 被调度到了一块，很容易出现 OOM。</li>
<li>在 TaskTracker 端，把资源强制划分为 map task slot 和 reduce task slot, 如果当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费，也就是前面提过的集群资源利用的问题。4. 源代码层面分析的时候，会发现代码非常的难读，常常因为一个 class 做了太多的事情，代码量达 3000 多行，造成 class 的任务不清晰，增加 bug 修复和版本维护的难度。</li>
<li>从操作的角度来看，现在的 Hadoop MapReduce 框架在有任何重要的或者不重要的变化 ( 例如 bug 修复，性能提升和特性化 ) 时，都会强制进行系统级别的升级更新。更糟的是，它不管用户的喜好，强制让分布式集群系统的每一个用户端同时更新。这些更新会让用户为了验证他们之前的应用程序是不是适用新的 Hadoop 版本而浪费大量时间。</li>
</ol>
<h3 id="新-Hadoop-Yarn-框架原理及运作机制"><a href="#新-Hadoop-Yarn-框架原理及运作机制" class="headerlink" title="新 Hadoop Yarn 框架原理及运作机制"></a>新 Hadoop Yarn 框架原理及运作机制</h3><p>从业界使用分布式系统的变化趋势和 hadoop 框架的长远发展来看，MapReduce 的 JobTracker/TaskTracker 机制需要大规模的调整来修复它在可扩展性，内存消耗，线程模型，可靠性和性能上的缺陷。在过去的几年中，hadoop 开发团队做了一些 bug 的修复，但是最近这些修复的成本越来越高，这表明对原框架做出改变的难度越来越大。</p>
<p>为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：</p>
<p><strong>图2：新的 Hadoop MapReduce 框架（Yarn）架构</strong><br><img src="/myimages/image002.jpg" alt="新的 Hadoop MapReduce 框架（Yarn）架构"></p>
<p>重构根本的思想是将 JobTracker 两个主要的功能分离成单独的组件，这两个功能是资源管理和任务调度 / 监控。新的资源管理器全局管理所有应用程序计算资源的分配，每一个应用的 ApplicationMaster 负责相应的调度和协调。一个应用程序无非是一个单独的传统的 MapReduce 任务或者是一个 DAG( 有向无环图 ) 任务。ResourceManager 和每一台机器的节点管理服务器能够管理用户在那台机器上的进程并能对计算进行组织。</p>
<p>事实上，每一个应用的 ApplicationMaster 是一个详细的框架库，它结合从 ResourceManager 获得的资源和 NodeManager 协同工作来运行和监控任务。</p>
<p>上图中 ResourceManager 支持分层级的应用队列，这些队列享有集群一定比例的资源。从某种意义上讲它就是一个纯粹的调度器，它在执行过程中不对应用进行监控和状态跟踪。同样，它也不能重启因应用失败或者硬件错误而运行失败的任务。</p>
<p>ResourceManager 是基于应用程序对资源的需求进行调度的 ; 每一个应用程序需要不同类型的资源因此就需要不同的容器。资源包括：内存，CPU，磁盘，网络等等。可以看出，这同现 Mapreduce 固定类型的资源使用模型有显著区别，它给集群的使用带来负面的影响。资源管理器提供一个调度策略的插件，它负责将集群资源分配给多个队列和应用程序。调度插件可以基于现有的能力调度和公平调度模型。</p>
<p>上图中 NodeManager 是每一台机器框架的代理，是执行应用程序的容器，监控应用程序的资源使用情况 (CPU，内存，硬盘，网络 ) 并且向调度器汇报。</p>
<p>每一个应用的 ApplicationMaster 的职责有：向调度器索要适当的资源容器，运行任务，跟踪应用程序的状态和监控它们的进程，处理任务的失败原因。</p>
<h3 id="新旧-Hadoop-MapReduce-框架比对"><a href="#新旧-Hadoop-MapReduce-框架比对" class="headerlink" title="新旧 Hadoop MapReduce 框架比对"></a>新旧 Hadoop MapReduce 框架比对</h3><p>让我们来对新旧 MapReduce 框架做详细的分析和对比，可以看到有以下几点显著变化：</p>
<p>首先客户端不变，其调用 API 及接口大部分保持兼容，这也是为了对开发使用者透明化，使其不必对原有代码做大的改变，但是原框架中核心的 JobTracker 和 TaskTracker 不见了，取而代之的是 ResourceManager, ApplicationMaster 与 NodeManager 三个部分。</p>
<p>我们来详细解释这三个部分，首先 ResourceManager 是一个中心的服务，它做的事情是调度、启动每一个 Job 所属的 ApplicationMaster、另外监控 ApplicationMaster 的存在情况。细心的读者会发现：Job 里面所在的 task 的监控、重启等等内容不见了。这就是 AppMst 存在的原因。ResourceManager 负责作业与资源的调度。接收 JobSubmitter 提交的作业，按照作业的上下文 (Context) 信息，以及从 NodeManager 收集来的状态信息，启动调度过程，分配一个 Container 作为 App Mstr</p>
<p>NodeManager 功能比较专一，就是负责 Container 状态的维护，并向 RM 保持心跳。</p>
<p>ApplicationMaster 负责一个 Job 生命周期内的所有工作，类似老的框架中 JobTracker。但注意每一个 Job（不是每一种）都有一个 ApplicationMaster，它可以运行在 ResourceManager 以外的机器上。</p>
<p>Yarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：</p>
<p>这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。<br>在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。<br>对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。<br>老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的运行状况，如果出问题，会将其在其他机器上重启。<br>Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>
<p>新的 Yarn 框架相对旧 MapRduce 框架而言，其配置文件 , 启停脚本及全局变量等也发生了一些变化，主要的改变如下：</p>
<p><strong>表1：新旧 Hadoop 脚本 / 变量 / 位置变化表</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">改变项</th>
<th style="text-align:left">原框架中</th>
<th style="text-align:left">新框架中（Yarm）</th>
<th style="text-align:left">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">配置文件位置</td>
<td style="text-align:left">${hadoop_home_dir}/conf</td>
<td style="text-align:left">${hadoop_home_dir}/etc/hadoop</td>
<td style="text-align:left">Yarn 框架也兼容老的 ${hadoop_home_dir}/conf 位置配置，启动时会检测是否存在老的 conf 目录，如果存在将加载 conf 目录下的配置，否则加载 etc 下配置</td>
</tr>
<tr>
<td style="text-align:left">启停脚本</td>
<td style="text-align:left">${hadoop_home_dir}/bin/start（stop）-all.sh</td>
<td style="text-align:left">${hadoop_home_dir}/sbin/start（stop）-dfs.sh ${hadoop_home_dir}/bin/start(stop)-all.sh</td>
<td style="text-align:left">新的 Yarn 框架中启动分布式文件系统和启动 Yarn 分离，启动 / 停止分布式文件系统的命令位于 ${hadoop_home_dir}/sbin 目录下，启动 / 停止 Yarn 框架位于 ${hadoop_home_dir}/bin/ 目录下</td>
</tr>
<tr>
<td style="text-align:left">JAVA_HOME 全局变量</td>
<td style="text-align:left">${hadoop_home_dir}/bin/start-all.sh 中</td>
<td style="text-align:left">${hadoop_home_dir}/etc/hadoop/hadoop-env.sh ${hadoop_home_dir}/etc/hadoop/Yarn-env.sh</td>
<td style="text-align:left">Yarn 框架中由于启动 hdfs 分布式文件系统和启动 MapReduce 框架分离，JAVA_HOME 需要在 hadoop-env.sh 和 Yarn-env.sh 中分别配置</td>
</tr>
<tr>
<td style="text-align:left">HADOOP_LOG_DIR 全局变量</td>
<td style="text-align:left">不需要配置</td>
<td style="text-align:left">${hadoop_home_dir}/etc/hadoop/hadoop-env.sh</td>
<td style="text-align:left">老框架在 LOG，conf，tmp 目录等均默认为脚本启动的当前目录下的 log,conf，tmp 子目录，Yarn 新框架中 Log 默认创建在 Hadoop 用户的 home 目录下的 log 子目录，因此最好在 ${hadoop_home_dir}/etc/hadoop/hadoop-env.sh 配置 HADOOP_LOG_DIR，否则有可能会因为你启动 hadoop 的用户的 .bashrc 或者 .bash_profile 中指定了其他的 PATH 变量而造成日志位置混乱，而该位置没有访问权限的话启动过程中会报错</td>
</tr>
</tbody>
</table>
<p>由于新的 Yarn 框架与原 Hadoop MapReduce 框架相比变化较大，核心的配置文件中很多项在新框架中已经废弃，而新框架中新增了很多其他配置项，看下表所示会更加清晰：</p>
<p><strong>表2:新旧 Hadoop 框架配置项变化表</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">配置文件</th>
<th style="text-align:left">配置项</th>
<th style="text-align:left">Hadoop 0.20.X配置</th>
<th style="text-align:left">Hadoop 0.23.X配置</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">core-site.xml</td>
<td style="text-align:left">系统默认分布式文件URL</td>
<td style="text-align:left">fs.default.name</td>
<td style="text-align:left">fs.defaultFS</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">hdfs-site.xml</td>
<td style="text-align:left">DFS name node 存放 name table 的目录</td>
<td style="text-align:left">dfs.name.dir</td>
<td style="text-align:left">dfs.namenode.name.dir</td>
<td style="text-align:left">新框架中 name node 分成 dfs.namenode.name.dir( 存放 naname table 和 dfs.namenode.edits.dir（存放 edit 文件），默认是同一个目录</td>
</tr>
<tr>
<td style="text-align:left">hdfs-site.xml</td>
<td style="text-align:left">DFS data node 存放数据block的目录</td>
<td style="text-align:left">dfs.data.dir</td>
<td style="text-align:left">dfs.datanode.data.dir</td>
<td style="text-align:left">新框架中 DataNode 增加更多细节配置，位于 dfs.datanode. 配置项下，如 dfs.datanode.data.dir.perm（datanode local 目录默认权限）；dfs.datanode.address（datanode 节点监听端口）；等</td>
</tr>
<tr>
<td style="text-align:left">hdfs-site.xml</td>
<td style="text-align:left">分布式文件系统数据复制块</td>
<td style="text-align:left">dfs.replication</td>
<td style="text-align:left">dfs.replication</td>
<td style="text-align:left">新框架与老框架一致，值建议配置为与分布式 cluster 中实际的 DataNode 主机数一致</td>
</tr>
<tr>
<td style="text-align:left">mapred-site.xml</td>
<td style="text-align:left">Job监控地址及端口</td>
<td style="text-align:left">mapred.job.tracker</td>
<td style="text-align:left">无</td>
<td style="text-align:left">新框架中已改为 Yarn-site.xml 中的 resouceManager 及 nodeManager 具体配置项，新框架中历史 job 的查询已从 Job tracker 剥离，归入单独的 mapreduce.jobtracker.jobhistory 相关配置，</td>
</tr>
<tr>
<td style="text-align:left">mapred-site.xml</td>
<td style="text-align:left">第三方MapReduce框架</td>
<td style="text-align:left">无</td>
<td style="text-align:left">mapreduce.framework.name</td>
<td style="text-align:left">新框架支持第三方 MapReduce 开发框架以支持如 SmartTalk/DGSG 等非 Yarn 架构，注意通常情况下这个配置的值都设置为 Yarn，如果没有配置这项，那么提交的 Yarn job 只会运行在 locale 模式，而不是分布式模式。</td>
</tr>
<tr>
<td style="text-align:left">yarm-site.xml</td>
<td style="text-align:left">The address of the applications manager interface in the RM</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.address</td>
<td style="text-align:left">新框架中 NodeManager 与 RM 通信的接口地址</td>
</tr>
<tr>
<td style="text-align:left">yarm-site.xml</td>
<td style="text-align:left">The address of the scheduler interface</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.scheduler.address</td>
<td style="text-align:left">同上，NodeManger 需要知道 RM 主机的 scheduler 调度服务接口地址</td>
</tr>
<tr>
<td style="text-align:left">yarm-site.xml</td>
<td style="text-align:left">The address of the RM web application</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.webapp.address</td>
<td style="text-align:left">新框架中各个 task 的资源调度及运行状况通过通过该 web 界面访问</td>
</tr>
<tr>
<td style="text-align:left">yarm-site.xml</td>
<td style="text-align:left">The address of the resource tracker interface</td>
<td style="text-align:left">无</td>
<td style="text-align:left">Yarn.resourcemanager.resource-tracker.address</td>
<td style="text-align:left">新框架中 NodeManager 需要向 RM 报告任务运行状态供 Resouce 跟踪，因此 NodeManager 节点主机需要知道 RM 主机的 tracker 接口地址</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/" data-id="civywpvq7001lcopvk8v83anv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-JobTracker-和-TaskTracker-概述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/JobTracker-和-TaskTracker-概述/" class="article-date">
  <time datetime="2016-11-26T05:57:46.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/JobTracker-和-TaskTracker-概述/">JobTracker 和 TaskTracker 概述</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Hadoop MapReduce 采用 Master/Slave 结构。</p>
<ul>
<li>Master：整个集群的全局管理者，功能包括：作业管理、状态监控和任务调度等，即 MapReduce 中的 JobTracker。</li>
<li>Slave：负责任务的执行和任务状态的回报，即 MapReduce 中的 TaskTracker。</li>
</ul>
<h3 id="JobTracker-剖析"><a href="#JobTracker-剖析" class="headerlink" title="JobTracker 剖析"></a>JobTracker 剖析</h3><ol>
<li>概述：JobTracker 是一个后台服务进程，启动之后，会一直监听并接受来自各个 TaskTracker 发送的心跳信息，包括资源使用情况和任务运行情况等信息。</li>
<li>功能：</li>
</ol>
<ul>
<li>作业控制：在 hadoop 中每个应用程序被表示成一个作业，每个作业又被分成多个任务，JobTracker 的作业控制模块则负责作业的分解和状态监控。最重要的是状态监控：主要包括TaskTracker状态监控、作业状态监控和任务状态监控。主要作用：容错和为任务调度提供决策依据。</li>
<li>资源管理</li>
</ul>
<h3 id="TaskTracker-剖析"><a href="#TaskTracker-剖析" class="headerlink" title="TaskTracker 剖析"></a>TaskTracker 剖析</h3><ol>
<li>概述：TaskTracker 是 JobTracker 和 Task 之间的桥梁，一方面，从 JobTracker 接受并执行各种命令：运行任务、提交任务、杀死任务等；另一方面，将本地节点上各个任务的状态通过心跳周期性汇报给 JobTracker。TaskTracker与JobTracker和Task之间采用RPC协议进行通信。</li>
<li>功能：</li>
</ol>
<ul>
<li>汇报心跳：Tracker周期性将所有节点上各种信息通过心跳机制汇报给JobTracker。这些信息包括两部分：<br>a. 机器级别信息：节点健康情况、资源使用情况等<br>b. 任务级别信息：任务执行进度、任务运行状态等</li>
<li>执行命令：JobTracker 会给 TaskTracker 下达各种命令，主要包括：启动任务、提交任务、杀死任务、杀死作业和重新初始化。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/JobTracker-和-TaskTracker-概述/" data-id="civywpvr10027copvfg08adag" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-浅谈-JobTracker-和-TaskTracker" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/浅谈-JobTracker-和-TaskTracker/" class="article-date">
  <time datetime="2016-11-26T03:47:30.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/浅谈-JobTracker-和-TaskTracker/">浅谈 JobTracker 和 TaskTracker</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>JobTracker 对应于 NameNode。TaskTracker 对应于 DataNode。<br>DataNode 和 NameNode 是针对数据存放而言的，JobTracker 和 TaskTracker 是对于 MapReduce 执行而言的。</p>
<p>MapReduce 中有几个主要概念：JobClient、JobTracker和TaskTracker。MapReduce 整体上可以分为这么几条执行线索：</p>
<ol>
<li>JobClient 会在用户端通过 JobClient 类将应用已经配置参数打包成 jar 文件存储到 HDFS，并把路径提交到 JobTracker，然后由 JobTracker 创建每一个 Task（即MapTask和ReduceTask），并将他们分发到各个 TaskTracker 服务中去执行</li>
<li>JobTracker 是一个 master 服务，软件启动之后 JobTracker 接受 Job，负责调度 Job 的每一个子任务 task 运行于 TaskTracker 上，并监控他们，如果发现有失败的 task 就重新运行它。一般情况下应该把 JobTracker 部署在单独的机器上。</li>
<li>TaskTracker 是运行在多个节点上的 slaver 服务，TaskTracker 主动与 JobTracker 通信，接受作业，并负责执行每一个任务。TaskTracker 都需要运行在 HDFS 的 DataNode 上。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/浅谈-JobTracker-和-TaskTracker/" data-id="civywpvxt00b5copvplixasdt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-MapReduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-MapReduce/" class="article-date">
  <time datetime="2016-11-26T02:35:50.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-MapReduce/">Hadoop MapReduce</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>MapReduce 是一种编程模型，用于大规模数据级（大于 1TB）的并行运算。概念“Map（映射）”和“Reduce（归约）”是它们的主要思想。谷歌在 2004 年发表了可以分析大量数据的 MapReduce 算法。每当你听到“大数据”这个词时，它指的是因为太大而让仅仅一台机器难以有效存储或分析的问题。MapReduce 通过把计算量分配给不同的计算机群，能够解决大部分和大数据有关的分析问题。Hadoop 提供了最受欢迎的利用 MapReduce 算法来管理大数据的开源方式。</p>
<p>所以通常来说，每当听到“大数据”，那也许意味着 Hadoop 被用来存储数据，也通常意味着数据的抽取和检索是用的 MapReduce。</p>
<h3 id="拆分-MapReduce-算法"><a href="#拆分-MapReduce-算法" class="headerlink" title="拆分 MapReduce 算法"></a>拆分 MapReduce 算法</h3><p>MapReduce 合并了两种经典函数：</p>
<p>映射（Mapping）：对集合里的每个目标应用同一个操作。即，如果你相把表单里的每个单元格乘以二，那么把这个函数单独的应用到每个单元格上的操作就属于 mapping。<br>化简（Reducing）：遍历结合中的元素来返回一个综合的结果。即，“输出表单里的一列数字的和”这个任务属于reducing。</p>
<h3 id="MapReduce-算法例子"><a href="#MapReduce-算法例子" class="headerlink" title="MapReduce 算法例子"></a>MapReduce 算法例子</h3><p>你想数一摞牌中有多少张黑桃，直观的方式是一张一张检查并且输出有多少张黑桃。MapReduce 方法则是：</p>
<ol>
<li>给在座的所有玩家分配这摞牌</li>
<li>让每个玩家数自己手中的牌有几张是黑桃，然后把这个数目汇报给你</li>
<li>你把所有玩家告诉你的数字加起来，得到最后的结果</li>
</ol>
<p>这不是一个严谨的例子，在这个例子中，人代表计算机，因为他们同时工作，所以他们是一个集群。在大多数实际应用中，我们假设数据已经在每台计算机上了-也就是说把牌分发并不是 MapReduce 的第一步。（事实上，在计算机集群中如何存储文件是 Hadoop 的真正核心。）<br>通过把牌分给多个玩家并且让他们各自数数，你就在并行执行运算，因为每个玩家都在同时计算。这同时把这项工作变成了分布式，因为多个不同的人在解决同一个问题的过程中并不需要知道他们的邻居在干什么。<br>通过告诉每个人数数，你对一项检查每张牌的任务进行了映射。你不会让他们把黑桃牌递给你，而是让他们把你想要的东西化简为一个数字。<br>如果有足够的人的话，问一些更有趣的问题就相当简单了-比如“一摞牌的平均值是什么”。你可以通过合并“所有牌的值的和是什么”及“我们有多少张牌”这两个问题来得到答案。用这个和除以牌的张数就得到了平均值。</p>
<h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><p>MapReduce 通过把对数据集的大规模操作分发给网络上的每个节点实现可靠性；每个节点会周期性的返回它所完成的工作和最新的状态。如果一个节点保持沉默超过一个预设的时间间隔，主节点记录下这个节点状态为死亡，并把分配给这个节点的数据发到别的节点。</p>
<p>MapReduce 提供了以下的主要功能：</p>
<ol>
<li>数据划分和任务调度：</li>
</ol>
<p>系统自动将一个作业（Job）待处理的大数据划分为很多数据块，每个数据块对应于一个计算任务（Task），并自动调去计算节点来处理相应的数据块。作业和任务调度功能主要负责分配和调度计算节点（Map节点或Reduce节点），同时负责监控这些节点的执行状态，并负责Map节点指定的同步控制。</p>
<ol>
<li>数据/代码互定位：</li>
</ol>
<p>为了减少数据通信，一个节本原则是本地化数据处理，即一个计算节点尽可能处理其本地磁盘上所分布存储的数据，这实现了代码向数据的迁移；当无法进行这种本地化处理数据处理时，再寻找其它可用节点并将数据从网络上送到该节点（数据向代码迁移），但尽可能从数据所在的本地机架上寻找可用节点以减少通信延迟。</p>
<ol>
<li>系统优化</li>
</ol>
<p>为了减少数据通信开销，中间结果数据进入 Reduce 节点前会进行一定的合并处理；一个 Reduce 节点所处理的数据可能会来自多个 Map 节点，为了避免 Reduce 计算阶段发生数据相关性，Map 节点输出的中间结果需要使用一定的策略进行适当的划分处理，保证相关性数据发送到同一个 Reduce 节点；此外，系统还进行一些计算性能优化处理，如对最慢的计算任务采用多备份执行、选最快完成者作为结果。</p>
<ol>
<li>出错检测和恢复</li>
</ol>
<p>以低端商用服务器构成的大规模MapReduce 计算集群中，节点硬件（主机、磁盘、内存等）出错和软件出错是常态，因此 MapReduce 需要能检测并隔离出错点，并调度分配新的节点接管出错节点的计算任务。同时，系统还将维护数据存储的可靠性，用多备份冗余存储机制提高数据存储的可靠性，并能及时检测和恢复出错的数据。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-MapReduce/" data-id="civywpvq0001hcopvnn5phdcr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-启动、关闭" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-启动、关闭/" class="article-date">
  <time datetime="2016-11-26T01:08:50.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-启动、关闭/">Hadoop 启动、关闭</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="适用版本"><a href="#适用版本" class="headerlink" title="适用版本"></a>适用版本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop version</span><br><span class="line">Hadoop 3.0.0-alpha1</span><br><span class="line">Source code repository https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3</span><br><span class="line">Compiled by andrew on 2016-08-30T07:02Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum f3a9644139eac17acbb91bfce7f68e2</span><br><span class="line">This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar</span><br></pre></td></tr></table></figure>
<h2 id="参考地址"><a href="#参考地址" class="headerlink" title="参考地址"></a>参考地址</h2><p><a href="http://hadoop.apache.org/docs/r3.0.0-alpha1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Slaves_File" target="_blank" rel="external">http://hadoop.apache.org/docs/r3.0.0-alpha1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Slaves_File</a></p>
<h2 id="Hadoop-Startup"><a href="#Hadoop-Startup" class="headerlink" title="Hadoop Startup"></a>Hadoop Startup</h2><ol>
<li>要启动 Hadooop cluster，需要同时启动 HDFS 和 YARN cluster.<br>第一次打开 HDFS，它必须先格式化它。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<ol>
<li>如果 etc/hadoop/workers 与 ssh 信任已经配置好了，所有的 HDFS processes 可以使用单一的脚本来启动</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/start-dfs.sh   #在NameNode 节点运行</span><br></pre></td></tr></table></figure>
<p>也可以逐个节点来启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hdfs --daemon start namenode   #Start HDFS NameNode</span><br><span class="line">$HADOOP_HOME/bin/hdfs --daemon start datanode   #Start HDFS DataNode</span><br></pre></td></tr></table></figure>
<ol>
<li>如果 etc/hadoop/workers 与 SSH 信任已经配置好了，所有的 YARN processes 可以使用单一的脚本来启动</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>也可以逐个节点来启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/yarn --daemon start resourcemanager    #使用如下命令运行指定的资源管理程序</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon start nodemanager   #在每个yarn节点启动NodeManager</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon start proxyserver</span><br></pre></td></tr></table></figure>
<ol>
<li>在指定的服务器运行如下命令启动 MapReduce JobHistory Server</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop-ShutDown"><a href="#Hadoop-ShutDown" class="headerlink" title="Hadoop ShutDown"></a>Hadoop ShutDown</h2><ol>
<li>如果 etc/hadoop/workers 与 SSH 信任已经配置好了，使用如下命令停止所有的 HDFS processes</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/stop-dfs.sh    #在 NameNode 节点运行</span><br></pre></td></tr></table></figure>
<p>同启动的时候一样，也可以逐个节点停止：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hdfs --daemon stop namenode    # 在 NameNode 节点运行</span><br><span class="line">$HADOOP_HOME/bin/hdfs --daemon stop datanode    # 在 DataNode 节点运行</span><br></pre></td></tr></table></figure>
<ol>
<li>如果 etc/hadoop/workers 与 SSH 信任已经配置好可，使用如下命令停止所有 YARN processes</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>
<p>也可以逐个节点停止：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/yarn --daemon stop resourcemanager</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon stop nodemanager</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon stop proxyserver</span><br></pre></td></tr></table></figure>
<ol>
<li>停止 MapReduce JobHistory Server</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-启动、关闭/" data-id="civywpvq3001icopvwbjg4pmh" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-SSH-无密码登录节点" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/25/SSH-无密码登录节点/" class="article-date">
  <time datetime="2016-11-25T07:29:47.000Z" itemprop="datePublished">2016-11-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/25/SSH-无密码登录节点/">SSH 无密码登录节点</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在配置 Hadoop 的过程中一个必要的步骤是配置 Mster 节点可以无密码 SSH 登录到各个 Slave 节点上。</p>
<p>如下说明配置步骤：</p>
<ol>
<li>生成 Master 节点的公匙（在 Master 节点的终端中执行）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh		#如果没有该目录，先执行一次 ssh localhost</span><br><span class="line">rm -rf ./id_rsa*	#删除之前生成的公钥（如果有）</span><br><span class="line">ssh-keygen -t rsa	#一直按回车就可以</span><br></pre></td></tr></table></figure>
<ol>
<li>配置 Master 节点可以无密码 SSH 本机（在 Master 节点的终端中执行）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ./id_rsa.pub &gt;&gt;./authorized_keys</span><br></pre></td></tr></table></figure>
<p>完成后可执行 ssh Master 验证一下（可能需要输入 yes，成功后执行 exit 返回原来的终端）。</p>
<ol>
<li>在 Master 节点将公钥传送到各个 Slave 节点</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa.pub root@slave1:/root/</span><br></pre></td></tr></table></figure>
<ol>
<li>在 Slave 节点上，将 Master SSH 公匙加入授权</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.ssh		#如果不存在该文件夹需要先创建，若存在则忽略</span><br><span class="line">cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys	</span><br><span class="line">rm ~/id_rsa.pub		#用完就可以删除了</span><br></pre></td></tr></table></figure>
<p>如果有其它 slave 节点，也要执行将 Master 公匙传送到其它 Slave 节点并授权的步骤。</p>
<hr>
<p>至此，在 Master 节点上就可以无密码 SSH 到各个 Slave 节点了。可以在 Master 节点上执行如下命令进行检验：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh slave1</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/25/SSH-无密码登录节点/" data-id="civywpvv40077copvnvmq0srz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-查找通过Yum安装的Java的安装路径" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/25/查找通过Yum安装的Java的安装路径/" class="article-date">
  <time datetime="2016-11-25T03:46:47.000Z" itemprop="datePublished">2016-11-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Centos-7/">Centos 7</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/25/查找通过Yum安装的Java的安装路径/">查找通过Yum安装的Java的安装路径</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>很多需要 Javac 的程序依赖于 JAVA_HOME 环境变量。<br>如果是手工下载源码安装的JDK，很容易知道 JAVA_HOME 的目录，那么 YUM 安装的 JDK，不需要配置 PATH，因为已经使用软链接做好了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon hadoop]# echo $PATH</span><br><span class="line">/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line">[root@bogon hadoop]# javac -version</span><br><span class="line">javac 1.8.0_111</span><br></pre></td></tr></table></figure>
<ol>
<li>YUM 安装 JDK</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y java*</span><br></pre></td></tr></table></figure>
<ol>
<li>查找 JAVA_HOME</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon hadoop]# whereis javac</span><br><span class="line">javac: /usr/bin/javac /usr/share/man/man1/javac.1.gz</span><br><span class="line">[root@bogon hadoop]# ls -l /usr/bin/javac</span><br><span class="line">lrwxrwxrwx. 1 root root 23 11月 23 12:11 /usr/bin/javac -&gt; /etc/alternatives/javac</span><br><span class="line">[root@bogon hadoop]# ls -l /etc/alternatives/javac</span><br><span class="line">lrwxrwxrwx. 1 root root 70 11月 23 12:11 /etc/alternatives/javac -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/bin/javac</span><br><span class="line">[root@bogon hadoop]# whereis java</span><br><span class="line">java: /usr/bin/java /usr/lib/java /etc/java /usr/share/java /usr/share/man/man1/java.1.gz</span><br><span class="line">[root@bogon hadoop]# ls -l /usr/bin/java</span><br><span class="line">lrwxrwxrwx. 1 root root 22 11月 23 12:07 /usr/bin/java -&gt; /etc/alternatives/java</span><br><span class="line">[root@bogon hadoop]# ls -l /etc/alternatives/java</span><br><span class="line">lrwxrwxrwx. 1 root root 73 11月 23 12:07 /etc/alternatives/java -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/jre/bin/java</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/25/查找通过Yum安装的Java的安装路径/" data-id="civywpvxq00b0copv2l4xjvcg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据库镜像-主备切换" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/11/数据库镜像-主备切换/" class="article-date">
  <time datetime="2016-11-11T06:04:59.000Z" itemprop="datePublished">2016-11-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/11/数据库镜像-主备切换/">数据库镜像-主备切换</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>高性能状态-主备切换（主机服务停止）</li>
</ol>
<p>主机服务停止，镜像（备机）上执行下列命令后备机状态会变为：<strong>主机 挂起/正在还原…</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER FORCE_SERVICE_ALLOW_DATA_LOSS;</span><br></pre></td></tr></table></figure></p>
<p>此时如原主机再启动服务，会显示挂起状态。执行下列命令后状态会变为：<strong>镜像 已同步/正在还原…</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER RESUME;</span><br></pre></td></tr></table></figure></p>
<p>如果要从原镜像机（即现在的主机）手动切换回镜像状态，需执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER SAFETY FULL;</span><br></pre></td></tr></table></figure></p>
<p>即将运行模式改为高安全，这时状态就会变回最初的状态（即原始的主机和备机）</p>
<ol>
<li>高性能状态下-主备切换（主机网络断开）<br>在原始的主机、备机状态下，将主机网络断开，在备机（镜像）上执行下列命令同样可以实现主备切换：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER FORCE_SERVICE_ALLOW_DATA_LOSS;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>但是此时的备机（镜像）虽然成为了主机，其运行模式为高安全模式，需要手动切换到高性能模式下。然后将主机联网后，在主机上执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER RESUME;</span><br></pre></td></tr></table></figure></p>
<p>此时主机变为镜像机（镜像，已同步/正在还原…）</p>
<p>高安全模式下，将原主机服务停止，镜像机自动转为主机，但运行模式为高安全模式，此时镜像（相对于现在为主机）是不能调整运行模式的。即不能从高安全调整为高性能模式。只有当原主机网络连通或服务开始运行后在镜像（相对于现在为主机）才可以调整运行模式，同时这时也不允许强制执行。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/11/数据库镜像-主备切换/" data-id="civywpvxh00alcopvvyz6iu83" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-系统时间与现在时间相差8小时解决方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/10/CentOS-系统时间与现在时间相差8小时解决方法/" class="article-date">
  <time datetime="2016-11-10T01:27:49.000Z" itemprop="datePublished">2016-11-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Centos-7/">Centos 7</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/10/CentOS-系统时间与现在时间相差8小时解决方法/">CentOS 系统时间与现在时间相差8小时解决方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天安装了一台 CentOS 7 系统，安装好之后发现时间与现在时间相差 8 小时，具体表现如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost 0900]# date</span><br><span class="line">2016年 11月 10日 星期四 17:24:18 CST</span><br><span class="line">[root@localhost 0900]# date -u</span><br><span class="line">2016年 11月 10日 星期四 09:24:22 UTC</span><br></pre></td></tr></table></figure>
<p>这是由于我们在安装系统的时候时区是上海，而 CentOS 默认 bios 时间是 UTC 时间，所以相差 8 小时。这个时候 bios 时间和系统时间不一致，一个代表 UTC 时间，一个代表 CST （+8时区），即上海时间。</p>
<p>下面是同步时间的解决方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # Linux 时区设置为上海</span><br><span class="line">ntpdate asia.pool.ntp.org # 对准时间，需要先安装ntp服务器，yum install ntp</span><br><span class="line">/sbin/hwclock --systohc # 设置硬件时间和系统时间一致并校准</span><br></pre></td></tr></table></figure>
<p>至此，linux 系统时间和计算机硬件时间都是都是 cst 时区了，并且为上海时区。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost 0900]# date -u</span><br><span class="line">2016年 11月 10日 星期四 01:25:25 UTC</span><br><span class="line">[root@localhost 0900]# date</span><br><span class="line">2016年 11月 10日 星期四 09:25:27 CST</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/10/CentOS-系统时间与现在时间相差8小时解决方法/" data-id="civywpvoo000jcopvfog1iilj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CREATE-INDEX" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/27/CREATE-INDEX/" class="article-date">
  <time datetime="2016-10-27T03:50:13.000Z" itemprop="datePublished">2016-10-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/27/CREATE-INDEX/">CREATE INDEX</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CREATE-INDEX"><a href="#CREATE-INDEX" class="headerlink" title="CREATE INDEX"></a>CREATE INDEX</h2><p>为给定表或视图创建索引。<br>只有表或视图的所有者才能为表创建索引。表或视图的所有者可以随时创建索引，无论表中是否有数据。可以通过指定限定的数据库名称，为另一个数据库中的表或视图视窗索引。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE [ UNIQUE ] [ CLUSTERED | NONCLUSTERED ] INDEX index_name</span><br><span class="line">    ON &#123; table | view &#125; ( column [ ASC | DESC ] [ ,...n ] )</span><br><span class="line">[ WITH &lt; index_option &gt; [ ,...n] ]</span><br><span class="line">[ ON filegroup ]</span><br><span class="line"></span><br><span class="line">&lt; index_option &gt; ::=</span><br><span class="line">    &#123; PAD_INDEX |</span><br><span class="line">        FILLFACTOR = fillfactor |</span><br><span class="line">        IGNORE_DUP_KEY |</span><br><span class="line">        DROP_EXISTING |</span><br><span class="line">    STATISTICS_NORECOMPUTE |</span><br><span class="line">    SORT_IN_TEMPDB </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><h4 id="UNIQUE"><a href="#UNIQUE" class="headerlink" title="UNIQUE"></a>UNIQUE</h4><p>为表或视图创建唯一索引（不允许存在索引值相同的两行）。视图上的聚簇索引必须是 UNIQUE 索引。<br>在创建索引时，如果数据已存在，SQL Server 会检查是否有重复值，并在每次使用 INSERT 或 UPDATE 语句添加数据时进行这种检查。<br>如果存在重复的键值，将取消 CREATE INDEX 语句，并返回错误信息，给出第一个重复值。<br>如果存在唯一索引，那么会产生重复键值的 UPDATE 或 INSERT 语句将回滚，SQL Server 将显示错误信息。即使 UPDATE 或 INSERT 语句更改了很多行但只产生一个重复值，也会出现这种情况。<br>如果在有唯一索引并指定了 IGNORE_DUP_KEY 子句情况下输入数据，则只有违反 UNIQUE 索引才会失败。在处理 UPDATE 语句时，IGNORE_DUP_KEY 不起作用。<br>SQL Server 不允许为已经包含重复值的列创建唯一索引，无论是否设置了 IGNORE_DUP_KEY。如果尝试这样做，SQL Server 会显示错误信息；重复值必须先删除，才能为这些列创建唯一索引。</p>
<h4 id="CLUSTERED"><a href="#CLUSTERED" class="headerlink" title="CLUSTERED"></a>CLUSTERED</h4><p>创建一个对象，其中行的物理排序与索引排序相同，并且聚簇索引的最低一级（页级）包含实际的数据行。一个表或视图只允许同时有一个聚簇索引。具有聚簇索引的视图称为索引视图。必须先为视图创建唯一聚簇索引，然后才能为该视图定义其它索引。</p>
<p>因为按照定义，聚簇索引的页级与其数据页相同，所以创建聚簇索引时使用 ON filegroup 子句实际上会将表从创建该表所用的文件移到新的文件组中。在特定的文件组上创建表或索引之前，应确认哪些文件组可用并且有足够的空间供索引使用。文件组的大小必须至少是整个表所需空间的 1.2 倍，这一点很重要。</p>
<h4 id="NONCLUSTERED"><a href="#NONCLUSTERED" class="headerlink" title="NONCLUSTERED"></a>NONCLUSTERED</h4><p>创建一个指定表的逻辑排序的对象。对于非聚簇索引，行的物理排序独立于索引排序。非聚簇所应的页级包含索引行。每个索引行均包含非聚簇键值和一个或多个行定位器（指向包含该值的行）。如果表没有聚簇索引行，行定位器就是行的磁盘地址。如果表有聚簇索引，行定位器就是该行的聚簇索引键。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/10/27/CREATE-INDEX/" data-id="civywpvoj000hcopv43cww5um" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Apache/">Apache</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Bat/">Bat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Centos-7/">Centos 7</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HUAWEI/">HUAWEI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hyper-V/">Hyper-V</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Iptables/">Iptables</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MikroTik/">MikroTik</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mysql/">Mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nagios/">Nagios</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx/">Nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Postfix/">Postfix</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis/">Redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/26/Hadoop-新-MapReduce-框架-Yarn-详解/">Hadoop 新 MapReduce 框架 Yarn 详解</a>
          </li>
        
          <li>
            <a href="/2016/11/26/JobTracker-和-TaskTracker-概述/">JobTracker 和 TaskTracker 概述</a>
          </li>
        
          <li>
            <a href="/2016/11/26/浅谈-JobTracker-和-TaskTracker/">浅谈 JobTracker 和 TaskTracker</a>
          </li>
        
          <li>
            <a href="/2016/11/26/Hadoop-MapReduce/">Hadoop MapReduce</a>
          </li>
        
          <li>
            <a href="/2016/11/26/Hadoop-启动、关闭/">Hadoop 启动、关闭</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 XiaoYong Hu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/About" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>