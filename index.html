<!DOCTYPE html>
<html>

<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?639ab28f32e0029ed25324113f0ff34a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


<head>
  <meta charset="utf-8">
  
  <title>运维生存时间</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="运维 生存时间 ttl op oa">
<meta property="og:type" content="website">
<meta property="og:title" content="运维生存时间">
<meta property="og:url" content="http://ttlop.com/index.html">
<meta property="og:site_name" content="运维生存时间">
<meta property="og:description" content="运维 生存时间 ttl op oa">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="运维生存时间">
<meta name="twitter:description" content="运维 生存时间 ttl op oa">
  
    <link rel="alternate" href="/atom.xml" title="运维生存时间" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">运维生存时间</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">业精于勤而荒于嬉，行成于思而毁于随</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/About">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://ttlop.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Python-编码" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/20/Python-编码/" class="article-date">
  <time datetime="2017-04-20T06:00:28.000Z" itemprop="datePublished">2017-04-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python/">Python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/04/20/Python-编码/">Python 编码</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Python由国外引入，在2.x版本中默认使用ASCII编码，此情况下，当输入中文字符时程序运行出错，究其原因是ASCII编码使用8位表示了所有的英文、符号、数字，但不包含中文。</p>
<p>后来引入万国码unicode。万国码规定最少使用两个字节，汉字使用3个字节。使用万国码可以标识世界上现有的所有语言，但存在一个弊端，英文、数字、符号等一个字节就可以标识的字符均使用至少两个字节标识，大大浪费了存储空间，由此引入了UTF-8编码。</p>
<p>UTF-8编码是对于unicode编码的加工，它规定了某些字符使用8位、某些使用16位、某些使用24位，大大节省了空间。GBK、GB2312与UTF-8编码类似，均是对于unicode编码的加工。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/04/20/Python-编码/" data-id="cj1q081ea0075dbpvym5tigrn" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-华为S系列交换机配置SSH登录" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/16/华为S系列交换机配置SSH登录/" class="article-date">
  <time datetime="2017-03-16T04:22:36.000Z" itemprop="datePublished">2017-03-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/HUAWEI/">HUAWEI</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/03/16/华为S系列交换机配置SSH登录/">华为S系列交换机配置SSH登录</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>配置思路</strong></p>
<ul>
<li>配置VTY用户界面</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">system-view</span><br><span class="line">user-interface vty 0 4</span><br><span class="line">authentication-mode aaa</span><br><span class="line">protocol inbound ssh</span><br><span class="line">quit</span><br></pre></td></tr></table></figure>
<ul>
<li>创建SSH用户，并配置其认证方式为Password认证</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">aaa</span><br><span class="line">local-user client001 password cipher xxxxxx</span><br><span class="line">local-user client001 privilege level 3</span><br><span class="line">local-user client001 service-type ssh</span><br><span class="line">quit</span><br><span class="line">ssh user client001 authentication-type password</span><br></pre></td></tr></table></figure>
<ul>
<li>使能Stelnet服务器功能</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stelnet server enable</span><br></pre></td></tr></table></figure>
<ul>
<li>配置SSH用户服务方式为STelnet</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh user client001 service-type stelnet</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/03/16/华为S系列交换机配置SSH登录/" data-id="cj1q081gn00aldbpvvagumbo3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Zabbix-监控-Windows-的-CPU-百分比" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/" class="article-date">
  <time datetime="2017-02-15T04:08:27.000Z" itemprop="datePublished">2017-02-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Zabbix/">Zabbix</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/">Zabbix 监控 Windows 的 CPU 百分比</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Zabbix 自带的模块没有 CPU 使用率（百分比）这个监控项，我们可以通过添加计数器的方式实现 CPU 百分比的监控。</p>
<p>在 Zabbix 的 WEB 端进行模板配置添加 CPU 百分比监控项目</p>
<p>*. 配置–模块–选择对应的模板–项目–创建项目</p>
<p>名称：CPU 百分比<br>键值：perf_counter[\Processor(_Total)\% Processor Time]<br>数据类型：数字的（浮点）<br>单位：%<br>数据更新间隔（秒）：30<br>应用集：CPU</p>
<p>*. 添加图形显示</p>
<p>*. 添加触发器CPU百分之85报警</p>
<p>表达式：{Windows 2008 R2:perf_counter[\Processor(_Total)\% Processor Time].avg(5m)}&gt;85</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/" data-id="cj1q081g1009qdbpvjweqrwlh" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Linux-访问-Windows-共享文件夹的两种方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/" class="article-date">
  <time datetime="2017-02-14T02:47:24.000Z" itemprop="datePublished">2017-02-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/">Linux 访问 Windows 共享文件夹的两种方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-mount-挂载"><a href="#1-mount-挂载" class="headerlink" title="1. mount 挂载"></a>1. mount 挂载</h2><p>首先创建被挂载的目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir windows</span><br></pre></td></tr></table></figure>
<p>将共享文件夹挂载到 windows 文件夹：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install cifs-utils  ## 安装必须组建</span><br><span class="line">mount.cifs //192.168.x.x/Backup ./windows -o user=backup  ## 挂载输入密码</span><br></pre></td></tr></table></figure>
<p>其中 /root/windows 表示挂载点，就是上面 windows 目录的完整路径。</p>
<h2 id="2-使用-samba-连接"><a href="#2-使用-samba-连接" class="headerlink" title="2. 使用 samba 连接"></a>2. 使用 samba 连接</h2><p>samba 就是让 windows 和 unix 系列 os 之间的文件可以互相访问的软件。使用 samba 访问 windows 的共享文件夹需要安装 smbclient。</p>
<p>安装好之后，就可以访问共享的文件了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smbclient --user=backup //192.168.x.x/Backup/Backup  ## 输入密码</span><br></pre></td></tr></table></figure>
<p>此时进入 smb 的命令操作空间，可以使用 help 来查看命令的使用。</p>
<p>也可以使用 help 查看单个命令的使用方式。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/" data-id="cj1q081c10046dbpvdcn5rjl3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-HTTP-请求" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/HTTP-请求/" class="article-date">
  <time datetime="2016-12-13T11:35:55.000Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/HTTP/">HTTP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/13/HTTP-请求/">HTTP 请求</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最常用请求：</p>
<ol>
<li>GET：请求获取由Request-URL所标识的资源</li>
<li>POST：在Request-URL所标识的资源后附加新的数据。例如：文件上传、提交表单</li>
</ol>
<p>都是为了实现服务器端的交互。用到的协议规则：</p>
<p>GET请求：</p>
<ol>
<li>第一行：方法 路径 协议版本（例如：GET / HTTP/1.1）</li>
<li>第二行：可以处理哪些类型的数据（例如：Accept: text/html, application/xhtml+xml, <em>/</em>）</li>
<li>第三行：可以接收的语言区域（例如：Accept-Language: zh-CN）</li>
<li>第四行：浏览器的客户端版本号</li>
<li>第五行：可以接收的编码格式（例如：Accept-Encoding: gzip, deflate）</li>
<li>第六行：表示访问的主机IP或者域名：Host</li>
<li>第七行：长连接（例如：Connection: Keep-Alive），由于每次传输都是建立TCP连接，消耗资源，所有有了长连接的机制，节省资源</li>
<li>第八行：Cookie（浏览器发送给服务器的内容）<br>。。。</li>
</ol>
<p>POST请求：</p>
<ol>
<li>第一行：方法 路径 协议版本（例如：POST / HTTP/1.1）</li>
<li>第二行：请求使用的方式（例如：x-requested-with: XMLHttpRequest）</li>
<li>第三行：可以接收的语言区域（例如：Accept-Language: zh-CN）</li>
<li>第四行：浏览器的请求来源，（例如：Referer: <a href="http://www.baidu.com/等）" target="_blank" rel="external">http://www.baidu.com/等）</a></li>
<li>第五行：Accept 可以处理哪些类型的数据<br>。。。</li>
</ol>
<p>响应：</p>
<ol>
<li>第一行：协议版本</li>
</ol>
<p>不常用请求：<br>HEAD OPTIONS PUT DELETE TRACE</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/12/13/HTTP-请求/" data-id="cj1q0819e001ndbpv13hb7eh4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-HTTP-协议基础" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/12/13/HTTP-协议基础/" class="article-date">
  <time datetime="2016-12-13T11:10:18.000Z" itemprop="datePublished">2016-12-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/HTTP/">HTTP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/12/13/HTTP-协议基础/">HTTP 协议基础</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>HTTP作为应用层协议，更加关注的是内容本身，即需要传输的内容。</p>
<p><strong>特点：</strong></p>
<ol>
<li><p>明文传输，安全性差。</p>
</li>
<li><p>无状态协议。</p>
</li>
<li><p>应用层协议，标准化协议1.1版本。</p>
</li>
</ol>
<p>每个页面会对应一个或多个请求。</p>
<p><strong>主要构成：</strong></p>
<ol>
<li><p>请求</p>
</li>
<li><p>响应</p>
</li>
</ol>
<p>均包含协议头、协议正文。</p>
<p><strong>举例：</strong></p>
<ol>
<li><p>打电话：发起一个通话的请求</p>
</li>
<li><p>响应：通话成功 占线 停机 不接听 。。。</p>
</li>
</ol>
<p>200：标准的成功响应码<br>302：重定向<br>404：页面不存在<br>。。。</p>
<p>通常来说1、2、3开头的响应均表示请求是成功的，4开头的表示请求存在问题，5开头的表示服务端存在问题。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/12/13/HTTP-协议基础/" data-id="cj1q08195001idbpvvem41oze" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-运行-Hadoop-伪分布式实例" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/29/运行-Hadoop-伪分布式实例/" class="article-date">
  <time datetime="2016-11-29T08:57:36.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/29/运行-Hadoop-伪分布式实例/">运行 Hadoop 伪分布式实例</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>伪分布式读取的是 HDFS 上的数据，要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 ~]# hdfs dfs -mkdir -p /user/root</span><br></pre></td></tr></table></figure>
<p>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/root/input 中。我们使用的是 root 用户，并且已创建相应的用户目录 /user/root，因此在此命令中就可以使用香断路径如 input，其对应的绝对路径就是 /user/root/input：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 ~]# hdfs dfs -mkdir input</span><br><span class="line">[root@slave3 ~]# hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>
<p>复制完成后，可以通过如下命令查看文件列表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 ~]# hdfs dfs -ls input</span><br><span class="line">Found 8 items</span><br><span class="line">-rw-r--r--   1 root supergroup       4436 2016-11-30 01:05 input/capacity-scheduler.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       1111 2016-11-30 01:05 input/core-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       9683 2016-11-30 01:05 input/hadoop-policy.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       1177 2016-11-30 01:05 input/hdfs-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup        620 2016-11-30 01:05 input/httpfs-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       3518 2016-11-30 01:05 input/kms-acls.xml</span><br><span class="line">-rw-r--r--   1 root supergroup       5933 2016-11-30 01:05 input/kms-site.xml</span><br><span class="line">-rw-r--r--   1 root supergroup        690 2016-11-30 01:05 input/yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>伪分布式云新 MapReduce 作业的方式跟单击模式相同，区别在于伪分布式读取的是 HDFS 中的文件（可以将单机目录中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 hadoop]# hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure>
<p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 hadoop]# hdfs dfs -cat output/*</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br><span class="line">1	dfs.namenode.name.dir</span><br><span class="line">1	dfs.datanode.data.dir</span><br></pre></td></tr></table></figure>
<p>我们也可以将运行结果取回本地：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 hadoop]# rm -rf ./output   # 先删除本地的 output 文件夹（如果存在的话）</span><br><span class="line">[root@slave3 hadoop]# hdfs dfs -get output ./output   # 将 HDFS 上的 output 文件夹拷贝到本机</span><br><span class="line">[root@slave3 hadoop]# cat ./output/*</span><br><span class="line">1	dfsadmin</span><br><span class="line">1	dfs.replication</span><br><span class="line">1	dfs.namenode.name.dir</span><br><span class="line">1	dfs.datanode.data.dir</span><br></pre></td></tr></table></figure>
<p>运行 Hadoop 程序时，为了防止覆盖结果，程序指定的输出目录（如 output）不能存在，否则会提示错误，因此运行前需要先删除输出目录。</p>
<p>上述通过 start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们也可以启动 YARN，让 YARN 来负责资源管理与任务调度。这里需要修改 mapred-site.xml 和 yarn-site.xml 两个配置文件：</p>
<p>mapred-site.xml 配置文件修改如下：（mapred-site.xml是从mapred-site.template拷贝过来的）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">              &lt;name&gt;mapreduce.admin.user.env&lt;/name&gt;</span><br><span class="line">	      &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">              &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">              &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>yarn-site.xml 配置文件修改如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>然后就可以启动 YARN 了（当然需要先执行 start-dfs.sh）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br><span class="line">mapred --daemon start historyserver  #开启历史任务查看</span><br></pre></td></tr></table></figure>
<p>启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 <strong>mapred.LocalJobRunner</strong> 在跑任务，启用 YARN 之后，是 YARN 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况。</p>
<p>但 YARN 主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑的稍慢些。因此在单机上是否开启 YARN 就看实际情况了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/29/运行-Hadoop-伪分布式实例/" data-id="cj1q081hh00bzdbpv3zekx192" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-安装教程-单机-伪分布式配置" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/29/Hadoop-安装教程-单机-伪分布式配置/" class="article-date">
  <time datetime="2016-11-29T07:35:26.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/29/Hadoop-安装教程-单机-伪分布式配置/">Hadoop 安装教程-单机/伪分布式配置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 系统版本</span><br><span class="line">[root@slave3 hadoop]# cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.2.1511 (Core) </span><br><span class="line"></span><br><span class="line"># 本机IP：192.168.1.43</span><br><span class="line"></span><br><span class="line"># 本机HostName：slave3</span><br><span class="line"></span><br><span class="line"># 使用 yum -y update 更新系统</span><br></pre></td></tr></table></figure>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul>
<li><strong>主机名修改及Host修改</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname slave3</span><br><span class="line">vim /etc/hosts # 最后增加一行 192.168.1.43	slave3</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>安装常用软件及java</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install java-1.8.0-openjdk*</span><br><span class="line">yum install wget vim net-tools</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>确认java安装目录</strong></li>
</ul>
<p>通过 whereis java 以及 ls -l 的方式定位 java 安装目录，这里是<br>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64<br>具体可以参考：<a href="http://ttlop.com/2016/11/25/%E6%9F%A5%E6%89%BE%E9%80%9A%E8%BF%87Yum%E5%AE%89%E8%A3%85%E7%9A%84Java%E7%9A%84%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/">http://ttlop.com/2016/11/25/%E6%9F%A5%E6%89%BE%E9%80%9A%E8%BF%87Yum%E5%AE%89%E8%A3%85%E7%9A%84Java%E7%9A%84%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/</a></p>
<ul>
<li><strong>hadoop下载及配置</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget http://apache.fayea.com/hadoop/common/hadoop-3.0.0-alpha1/hadoop-3.0.0-alpha1.tar.gz</span><br><span class="line"># 解压</span><br><span class="line">tar zxvf hadoop-3.0.0-alpha1.tar.gz</span><br><span class="line"># 移动</span><br><span class="line">mv hadoop-3.0.0-alpha1 /usr/local/hadoop</span><br><span class="line"># 修改权限及确认</span><br><span class="line">cd /usr/local &amp;&amp; chown -R root.root hadoop &amp;&amp; ls -l hadoop &amp;&amp; cd hadoop &amp;&amp; ls -al</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>SSH 权限修改</strong></li>
</ul>
<p>通过ssh-keygen 及 authorized_keys 文件修改SSH登录权限。<br>具体可以参考：<a href="http://ttlop.com/2016/11/25/SSH-%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E8%8A%82%E7%82%B9/">http://ttlop.com/2016/11/25/SSH-%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E8%8A%82%E7%82%B9/</a></p>
<ul>
<li><strong>关闭防火墙即selinux</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 这里为测试环境，我们将安全选项都关闭</span><br><span class="line">setenforce 8</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>配置修改</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># PATH 修改（当前终端有效）</span><br><span class="line">export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin</span><br><span class="line"># hadoop 中 JAVA_HOME修改</span><br><span class="line">vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh</span><br><span class="line">增加  export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>单机配置测试</strong></li>
</ul>
<p>Hadoop 默认模式为非分布式模式，无需进行其它配置即可运行。非分布式即单 Java 进程，方便进行调试。<br>以下面为例，我们选择运行 grep 例子，我们将 input 文件夹中的所有文件作为输入，筛选当前符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">mkdir ./input</span><br><span class="line">cp ./etc/hadoop/*.xml ./input   # 将配置文件作为输入文件</span><br><span class="line">./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output &apos;dfs[a-z.]+&apos;</span><br><span class="line">cat ./output/*  # 查看运行结果</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>伪分布式配置</strong></li>
</ul>
<p>Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。</p>
<p>Hadoop 的配置文件位于 $HADOOP_HOME/etc/hadoop中，伪分布式需要修改2个配置文件 core-site.xml和hdfs-site.xml。Hadoop 的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。<br>如下是修改后的 core-site.xml文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/home/hadoop/tmp&lt;/value&gt;</span><br><span class="line">             &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<p>如下是修改后的 hdfs-site.xml文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/home/hadoop/tmp/dfs/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">             &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">             &lt;value&gt;file:/home/hadoop/tmp/dfs/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<p>配置完成后，执行 NameNode 的格式化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>接着开启 NameNode 和 DataNode 守护进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@slave3 dfs]# jps</span><br><span class="line">50290 SecondaryNameNode</span><br><span class="line">50617 Jps</span><br><span class="line">50090 DataNode</span><br><span class="line">49995 NameNode</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/29/Hadoop-安装教程-单机-伪分布式配置/" data-id="cj1q0819u0020dbpv56989yed" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Centos-7-LVM-磁盘扩容" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/29/Centos-7-LVM-磁盘扩容/" class="article-date">
  <time datetime="2016-11-29T05:55:06.000Z" itemprop="datePublished">2016-11-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Centos-7/">Centos 7</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/29/Centos-7-LVM-磁盘扩容/">Centos 7 LVM 磁盘扩容</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Hyper 主机有一台 Centos 7 虚拟机，系统是运行 Hadoop 环境，因为调试需要，准备扩容磁盘来增加空间。如何增加虚拟机磁盘空间的操作方法这里不作过多说明，都是图形化操作界面。</p>
<p>这里我们重点在介绍在 Centos 7中的操作。</p>
<ul>
<li><strong>查看现有的硬盘分区（现有空间没有变大）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# df -h</span><br><span class="line">文件系统                 容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root   50G  5.2G   45G   11% /</span><br><span class="line">devtmpfs                 1.9G     0  1.9G    0% /dev</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /dev/shm</span><br><span class="line">tmpfs                    1.9G  8.3M  1.9G    1% /run</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-home   73G   33M   73G    1% /home</span><br><span class="line">/dev/sda1                497M  152M  346M   31% /boot</span><br><span class="line">tmpfs                    379M     0  379M    0% /run/user/0</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>对新增加的硬盘空间做新增分区（硬盘数没有增加，增加的是空间）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# fdisk -l</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sda：818.2 GB, 818191269888 字节，1598029824 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x0009a639</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     1026047      512000   83  Linux</span><br><span class="line">/dev/sda2         1026048   266338303   132656128   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-swap：4177 MB, 4177526784 字节，8159232 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-root：53.7 GB, 53687091200 字节，104857600 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-home：78.0 GB, 77972111360 字节，152289280 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# fdisk /dev/sda</span><br><span class="line"></span><br><span class="line">The device presents a logical sector size that is smaller than</span><br><span class="line">the physical sector size. Aligning to a physical sector (or optimal</span><br><span class="line">I/O) size boundary is recommended, or performance may be impacted.</span><br><span class="line">欢迎使用 fdisk (util-linux 2.23.2)。</span><br><span class="line"></span><br><span class="line">更改将停留在内存中，直到您决定将更改写入磁盘。</span><br><span class="line">使用写入命令前请三思。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：n（说明：新增分区）</span><br><span class="line">Partition type:</span><br><span class="line">   p   primary (2 primary, 0 extended, 2 free)</span><br><span class="line">   e   extended</span><br><span class="line">Select (default p): p（说明：主分区）</span><br><span class="line">分区号 (3,4，默认 3)：（说明：新增分区号（1，2默认已经使用））</span><br><span class="line">起始 扇区 (266338304-1598029823，默认为 266338304)：（说明：默认回车最小）</span><br><span class="line">将使用默认值 266338304</span><br><span class="line">Last 扇区, +扇区 or +size&#123;K,M,G&#125; (266338304-1598029823，默认为 1598029823)：（说明：默认回车最大）</span><br><span class="line">将使用默认值 1598029823</span><br><span class="line">分区 3 已设置为 Linux 类型，大小设为 635 GiB</span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：t（说明：修改分区类型）</span><br><span class="line">分区号 (1-3，默认 3)：3（说明：修改分区类型对应的分区号）</span><br><span class="line">Hex 代码(输入 L 列出所有代码)：8e（说明：8e是lvm磁盘类型）</span><br><span class="line">已将分区“Linux”的类型更改为“Linux LVM”</span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：p（说明：打印分区表）</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sda：818.2 GB, 818191269888 字节，1598029824 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x0009a639</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     1026047      512000   83  Linux</span><br><span class="line">/dev/sda2         1026048   266338303   132656128   8e  Linux LVM</span><br><span class="line">/dev/sda3       266338304  1598029823   665845760   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">命令(输入 m 获取帮助)：w（说明：保存退出）</span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line"></span><br><span class="line">WARNING: Re-reading the partition table failed with error 16: 设备或资源忙.</span><br><span class="line">The kernel still uses the old table. The new table will be used at</span><br><span class="line">the next reboot or after you run partprobe(8) or kpartx(8)</span><br><span class="line">正在同步磁盘。</span><br><span class="line">[root@slave2 ~]#</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>重启系统</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# reboot</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查看硬盘情况（核对刚才所做的分区操作是否保存成功）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# fdisk -l</span><br><span class="line"></span><br><span class="line">磁盘 /dev/sda：818.2 GB, 818191269888 字节，1598029824 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line">磁盘标签类型：dos</span><br><span class="line">磁盘标识符：0x0009a639</span><br><span class="line"></span><br><span class="line">   设备 Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048     1026047      512000   83  Linux</span><br><span class="line">/dev/sda2         1026048   266338303   132656128   8e  Linux LVM</span><br><span class="line">/dev/sda3       266338304  1598029823   665845760   8e  Linux LVM</span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-swap：4177 MB, 4177526784 字节，8159232 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-root：53.7 GB, 53687091200 字节，104857600 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">磁盘 /dev/mapper/centos-home：78.0 GB, 77972111360 字节，152289280 个扇区</span><br><span class="line">Units = 扇区 of 1 * 512 = 512 bytes</span><br><span class="line">扇区大小(逻辑/物理)：512 字节 / 4096 字节</span><br><span class="line">I/O 大小(最小/最佳)：4096 字节 / 4096 字节</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查看当前分区类型</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# df -T /dev/sda1</span><br><span class="line">文件系统       类型  1K-块   已用   可用 已用% 挂载点</span><br><span class="line">/dev/sda1      xfs  508588 154808 353780   31% /boot</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>创建文件系统在新的磁盘上</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# mkfs.xfs /dev/sda3</span><br><span class="line">meta-data=/dev/sda3              isize=256    agcount=4, agsize=41615360 blks</span><br><span class="line">         =                       sectsz=4096  attr=2, projid32bit=1</span><br><span class="line">         =                       crc=0        finobt=0</span><br><span class="line">data     =                       bsize=4096   blocks=166461440, imaxpct=25</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=0</span><br><span class="line">log      =internal log           bsize=4096   blocks=81280, version=2</span><br><span class="line">         =                       sectsz=4096  sunit=1 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>创建pv、查看pv状态（PV组成VG，VG组成LV）</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda2</span><br><span class="line">  VG Name               centos</span><br><span class="line">  PV Size               126.51 GiB / not usable 3.00 MiB</span><br><span class="line">  Allocatable           yes (but full)</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              32386</span><br><span class="line">  Free PE               0</span><br><span class="line">  Allocated PE          32386</span><br><span class="line">  PV UUID               ddZZPI-6Wty-4qgS-RPMY-Gdsd-jih4-cqP0vQ</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# pvcreate /dev/sda3</span><br><span class="line">  Device /dev/sda3 not found (or ignored by filtering).</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# pvdisplay </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda2</span><br><span class="line">  VG Name               centos</span><br><span class="line">  PV Size               126.51 GiB / not usable 3.00 MiB</span><br><span class="line">  Allocatable           yes (but full)</span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              32386</span><br><span class="line">  Free PE               0</span><br><span class="line">  Allocated PE          32386</span><br><span class="line">  PV UUID               ddZZPI-6Wty-4qgS-RPMY-Gdsd-jih4-cqP0vQ</span><br><span class="line">   </span><br><span class="line">  --- Physical volume ---</span><br><span class="line">  PV Name               /dev/sda3</span><br><span class="line">  VG Name               centos</span><br><span class="line">  PV Size               635.00 GiB / not usable 4.00 MiB</span><br><span class="line">  Allocatable           yes </span><br><span class="line">  PE Size               4.00 MiB</span><br><span class="line">  Total PE              162559</span><br><span class="line">  Free PE               162559</span><br><span class="line">  Allocated PE          0</span><br><span class="line">  PV UUID               OiezFh-mTSY-u0Xk-pADo-rJsc-dfT5-kfCUCF</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>刚创建的PV加入相应的VG</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# vgextend centos /dev/sda3</span><br><span class="line">WARNING: xfs signature detected on /dev/sda3 at offset 0. Wipe it? [y/n]: y</span><br><span class="line">  Wiping xfs signature on /dev/sda3.</span><br><span class="line">  Physical volume &quot;/dev/sda3&quot; successfully created</span><br><span class="line">  Volume group &quot;centos&quot; successfully extended</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>查看LV状态，把VG加入到LV</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# lvdisplay </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/centos/swap</span><br><span class="line">  LV Name                swap</span><br><span class="line">  VG Name                centos</span><br><span class="line">  LV UUID                x2Acgw-2v1S-HrpP-rJCW-b259-RivD-qF6fdC</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time bogon, 2016-11-23 10:32:37 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  # open                 2</span><br><span class="line">  LV Size                3.89 GiB</span><br><span class="line">  Current LE             996</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:0</span><br><span class="line">   </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/centos/home</span><br><span class="line">  LV Name                home</span><br><span class="line">  VG Name                centos</span><br><span class="line">  LV UUID                lbxRvi-O3Th-EAdc-2dKL-Pf13-YvQn-Om88WI</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time bogon, 2016-11-23 10:32:37 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  # open                 1</span><br><span class="line">  LV Size                72.62 GiB</span><br><span class="line">  Current LE             18590</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:2</span><br><span class="line">   </span><br><span class="line">  --- Logical volume ---</span><br><span class="line">  LV Path                /dev/centos/root</span><br><span class="line">  LV Name                root</span><br><span class="line">  VG Name                centos</span><br><span class="line">  LV UUID                oqgktg-XpOf-2HXX-rrLM-pGW0-ebs0-e2FR8j</span><br><span class="line">  LV Write Access        read/write</span><br><span class="line">  LV Creation host, time bogon, 2016-11-23 10:32:39 +0800</span><br><span class="line">  LV Status              available</span><br><span class="line">  # open                 1</span><br><span class="line">  LV Size                50.00 GiB</span><br><span class="line">  Current LE             12800</span><br><span class="line">  Segments               1</span><br><span class="line">  Allocation             inherit</span><br><span class="line">  Read ahead sectors     auto</span><br><span class="line">  - currently set to     8192</span><br><span class="line">  Block device           253:1</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# lvextend -l +162559 /dev/mapper/centos-home </span><br><span class="line">  Size of logical volume centos/home changed from 72.62 GiB (18590 extents) to 707.61 GiB (181149 extents).</span><br><span class="line">  Logical volume home successfully resized.</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>调整文件系统大小</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@slave2 ~]# xfs_growfs /dev/mapper/centos-home </span><br><span class="line">meta-data=/dev/mapper/centos-home isize=256    agcount=4, agsize=4759040 blks</span><br><span class="line">         =                       sectsz=512   attr=2, projid32bit=1</span><br><span class="line">         =                       crc=0        finobt=0</span><br><span class="line">data     =                       bsize=4096   blocks=19036160, imaxpct=25</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=0</span><br><span class="line">log      =internal               bsize=4096   blocks=9295, version=2</span><br><span class="line">         =                       sectsz=512   sunit=0 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br><span class="line">data blocks changed from 19036160 to 185496576</span><br><span class="line">[root@slave2 ~]# df -h</span><br><span class="line">文件系统                 容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root   50G  5.2G   45G   11% /</span><br><span class="line">devtmpfs                 1.9G     0  1.9G    0% /dev</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /dev/shm</span><br><span class="line">tmpfs                    1.9G  8.3M  1.9G    1% /run</span><br><span class="line">tmpfs                    1.9G     0  1.9G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-home  708G   34M  708G    1% /home</span><br><span class="line">/dev/sda1                497M  152M  346M   31% /boot</span><br><span class="line">tmpfs                    379M     0  379M    0% /run/user/0</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/29/Centos-7-LVM-磁盘扩容/" data-id="cj1q0817w000kdbpv8vvzcfj9" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-Yarn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-Yarn/" class="article-date">
  <time datetime="2016-11-26T08:14:13.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-Yarn/">Hadoop Yarn</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Yarn-简介"><a href="#Yarn-简介" class="headerlink" title="Yarn 简介"></a>Yarn 简介</h1><p>YARN的基本思想是将 JobTracker 的两个主要功能（资源管理和作业调度/监控）分离，主要方法是创建一个全局的ResourceManager（RM）和若干个针对应用程序的ApplicationMaster（AM）。这里的应用程序是指传统的MapReduce作业或作业的DAG（有向无环图）。</p>
<p>YARN 分层结构的本质是 ResourceManager。这个实体控制整个集群并管理应用程序向基础计算资源的分配。ResourceManager 将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）。ResourceManager 还与 ApplicationMaster 一起分配资源，与 NodeManager 一起启动和监视它们的基础应用程序。在此上下文中，ApplicationMaster 承担了以前的 TaskTracker 的一些角色，ResourceManager 承担了 JobTracker 的角色。<br>ApplicationMaster 管理一个在 YARN 内运行的应用程序的每个实例。ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）。请注意，尽管目前的资源更加传统（CPU 核心、内存），但未来会带来基于手头任务的新资源类型（比如图形处理单元或专用处理设备）。从 YARN 角度讲，ApplicationMaster 是用户代码，因此存在潜在的安全问题。YARN 假设 ApplicationMaster 存在错误或者甚至是恶意的，因此将它们当作无特权的代码对待。<br>NodeManager 管理一个 YARN 集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。MRv1 通过插槽管理 Map 和 Reduce 任务的执行，而 NodeManager 管理抽象容器，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源。YARN 继续使用 HDFS 层。它的主要 NameNode 用于元数据服务，而 DataNode 用于分散在一个集群中的复制存储服务。<br>要使用一个 YARN 集群，首先需要来自包含一个应用程序的客户的请求。ResourceManager 协商一个容器的必要资源，启动一个 ApplicationMaster 来表示已提交的应用程序。通过使用一个资源请求协议，ApplicationMaster 协商每个节点上供应用程序使用的资源容器。执行应用程序时，ApplicationMaster 监视容器直到完成。当应用程序完成时，ApplicationMaster 从 ResourceManager 注销其容器，执行周期就完成了。</p>
<h2 id="MRv1-的缺陷"><a href="#MRv1-的缺陷" class="headerlink" title="MRv1 的缺陷"></a>MRv1 的缺陷</h2><p>MapReduce 的第一个版本既有优点也有缺点。MRv1 是目前使用的标准的大数据处理系统。但是，这种架构存在不足，主要表现在大型集群上。当集群包含的节点超过 4,000 个时（其中每个节点可能是多核的），就会表现出一定的不可预测性。其中一个最大的问题是级联故障，由于要尝试复制数据和重载活动的节点，所以一个故障会通过网络泛洪形式导致整个集群严重恶化。<br>但 MRv1 的最大问题是多租户。随着集群规模的增加，一种可取的方式是为这些集群采用各种不同的模型。MRv1 的节点专用于 Hadoop，所以可以改变它们的用途以用于其他应用程序和工作负载。当大数据和 Hadoop 成为云部署中一个更重要的使用模型时，这种能力也会增强，因为它允许在服务器上对 Hadoop 进行物理化，而无需虚拟化且不会增加管理、计算和输入/输出开销。</p>
<h2 id="Yarn的优点"><a href="#Yarn的优点" class="headerlink" title="Yarn的优点"></a>Yarn的优点</h2><p>大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。<br>在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。<br>对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。<br>老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的运行状况，如果出问题，会将其在其他机器上重启。<br>Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>
<h2 id="YARN的核心思想"><a href="#YARN的核心思想" class="headerlink" title="YARN的核心思想"></a>YARN的核心思想</h2><p>将JobTracker和TaskTacker进行分离，它由下面几大构成组件：<br>a. 一个全局的资源管理器 ResourceManager<br>b. ResourceManager的每个节点代理 NodeManager<br>c. 表示每个应用的 ApplicationMaster<br>d. 每一个ApplicationMaster拥有多个Container在NodeManager上运行[2]  </p>
<h1 id="YARN的主要架构"><a href="#YARN的主要架构" class="headerlink" title="YARN的主要架构"></a>YARN的主要架构</h1><h2 id="ResourceManager（RM）"><a href="#ResourceManager（RM）" class="headerlink" title="ResourceManager（RM）"></a>ResourceManager（RM）</h2><p>RM是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，ASM）。<br>调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。需要注意的是，该调度器是一个“纯调度器”，它不再从事任何与具体应用程序相关的工作，比如不负责监控或者跟踪应用的执行状态等，也不负责重新启动因应用执行失败或者硬件故障而产生的失败任务，这些均交由应用程序相关的ApplicationMaster完成。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位用一个抽象概念“资源容器”（Resource Container，简称Container）表示，Container是一个动态资源分配单位，它将内存、CPU、磁盘、网络等资源封装在一起，从而限定每个任务使用的资源量。此外，该调度器是一个可插拔的组件，用户可根据自己的需要设计新的调度器，YARN提供了多种直接可用的调度器，比如Fair Scheduler和Capacity Scheduler等。<br>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重新启动它等。</p>
<h2 id="ApplicationMaster（AM）"><a href="#ApplicationMaster（AM）" class="headerlink" title="ApplicationMaster（AM）"></a>ApplicationMaster（AM）</h2><p>用户提交的每个应用程序均包含一个AM，主要功能包括：<br>与RM调度器协商以获取资源（用Container表示）；<br>将得到的任务进一步分配给内部的任务(资源的二次分配)；<br>与NM通信以启动/停止任务；<br>监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。<br>当前YARN自带了两个AM实现，一个是用于演示AM编写方法的实例程序distributedshell，它可以申请一定数目的Container以并行运行一个Shell命令或者Shell脚本；另一个是运行MapReduce应用程序的AM—MRAppMaster。<br>注：RM只负责监控AM，在AM运行失败时候启动它，RM并不负责AM内部任务的容错，这由AM来完成。</p>
<h2 id="NodeManager（NM）"><a href="#NodeManager（NM）" class="headerlink" title="NodeManager（NM）"></a>NodeManager（NM）</h2><p>NM是每个节点上的资源和任务管理器，一方面，它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，它接收并处理来自AM的Container启动/停止等各种请求</p>
<h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h2><p>Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container表示。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。<br>注：1. Container不同于MRv1中的slot，它是一个动态资源划分单位，是根据应用程序的需求动态生成的。</p>
<ol>
<li>现在YARN仅支持CPU和内存两种资源，且使用了轻量级资源隔离机制Cgroups进行资源隔离。<br>YARN的资源管理和执行框架都是按主/从范例实现的——Slave —节点管理器（NM）运行、监控每个节点，并向集群的Master—资源管理器(RM)报告资源的可用性状态，资源管理器最终为系统里所有应用分配资源。<br>特定应用的执行由ApplicationMaster控制，ApplicationMaster负责将一个应用分割成多个任务，并和资源管理器协调执行所需的资源，资源一旦分配好，ApplicationMaster就和节点管理器一起安排、执行、监控独立的应用任务。<br>需要说明的是， YARN不同服务组件的通信方式采用了事件驱动的异步并发机制，这样可以简化系统的设计。</li>
</ol>
<h1 id="YARN架构简析"><a href="#YARN架构简析" class="headerlink" title="YARN架构简析"></a>YARN架构简析</h1><h2 id="集中式架构"><a href="#集中式架构" class="headerlink" title="集中式架构"></a>集中式架构</h2><p>集中式调度器(Monolithic Scheduler)的特点是，资源的调度和应用程序的管理功能全部放到一个进程中完成，开源界典型的代表是MRv1 JobTracker的实现。这样设计的缺点很明显，扩展性差：首先，集群规模受限；其次，新的调度策略难以融入到现有代码中，比如之前仅支持MapReduce作业，现在要支持流式作业，而将流式作业的调度策略嵌入到中央调度其中是一项很难的工作。</p>
<h2 id="双层调度架构"><a href="#双层调度架构" class="headerlink" title="双层调度架构"></a>双层调度架构</h2><p>为了克服集中式调度器的不足，双层调度器是一种很容易被想到的解决之道，它可看作是一种分而治之的机制或者是策略下放机制：双层调度器仍保留一个经简化的集中式资源调度器，但具体任务相关的调度策略则下放到各个应用程序调度器完成。这种调度器的典型代表是Mesos。Mesos调度器由两部分组成，分别是资源调度器和框架(应用程序)调度器,其中，资源调度器负责将集群中的资源分配给各个框架(应用程序),而框架(应用程序)调度器负责将资源进一步分配给内部的各个任务，用户很容易将一种框架或者系统接入Mesos.<br>双层调度器的特点是：各个框架调度器并不知道整个集群资源使用情况，只是被动地接受资源；资源调度器仅将可用的资源推送给各个框架，而由框架自己选择是使用还是拒绝这些资源；一旦框架接受到新资源，再进一步将资源分配给其内部的任务，进而实现双层调度。然而这种调度器也是有缺点，主要表现在以下两个方面:1.各个框架无法知道整个集群的实时资源使用情况；采用悲观锁，并发粒度小。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-Yarn/" data-id="cj1q0819m001vdbpvm2w3inxp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Apache/">Apache</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Bat/">Bat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Centos-7/">Centos 7</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTTP/">HTTP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HUAWEI/">HUAWEI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hyper-V/">Hyper-V</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Iptables/">Iptables</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MikroTik/">MikroTik</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mysql/">Mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nagios/">Nagios</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx/">Nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Postfix/">Postfix</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis/">Redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/04/20/Python-编码/">Python 编码</a>
          </li>
        
          <li>
            <a href="/2017/03/16/华为S系列交换机配置SSH登录/">华为S系列交换机配置SSH登录</a>
          </li>
        
          <li>
            <a href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/">Zabbix 监控 Windows 的 CPU 百分比</a>
          </li>
        
          <li>
            <a href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/">Linux 访问 Windows 共享文件夹的两种方法</a>
          </li>
        
          <li>
            <a href="/2016/12/13/HTTP-请求/">HTTP 请求</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 XiaoYong Hu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/About" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>