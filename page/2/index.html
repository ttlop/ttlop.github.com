<!DOCTYPE html>
<html>

<script type="text/javascript">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?639ab28f32e0029ed25324113f0ff34a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


<head>
  <meta charset="utf-8">
  
  <title>运维生存时间</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="运维 生存时间 ttl op oa">
<meta property="og:type" content="website">
<meta property="og:title" content="运维生存时间">
<meta property="og:url" content="http://ttlop.com/page/2/index.html">
<meta property="og:site_name" content="运维生存时间">
<meta property="og:description" content="运维 生存时间 ttl op oa">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="运维生存时间">
<meta name="twitter:description" content="运维 生存时间 ttl op oa">
  
    <link rel="alternate" href="/atom.xml" title="运维生存时间" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">运维生存时间</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">业精于勤而荒于嬉，行成于思而毁于随</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/About">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://ttlop.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-JobTracker-和-TaskTracker-概述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/JobTracker-和-TaskTracker-概述/" class="article-date">
  <time datetime="2016-11-26T05:57:46.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/JobTracker-和-TaskTracker-概述/">JobTracker 和 TaskTracker 概述</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Hadoop MapReduce 采用 Master/Slave 结构。</p>
<ul>
<li>Master：整个集群的全局管理者，功能包括：作业管理、状态监控和任务调度等，即 MapReduce 中的 JobTracker。</li>
<li>Slave：负责任务的执行和任务状态的回报，即 MapReduce 中的 TaskTracker。</li>
</ul>
<h3 id="JobTracker-剖析"><a href="#JobTracker-剖析" class="headerlink" title="JobTracker 剖析"></a>JobTracker 剖析</h3><ol>
<li>概述：JobTracker 是一个后台服务进程，启动之后，会一直监听并接受来自各个 TaskTracker 发送的心跳信息，包括资源使用情况和任务运行情况等信息。</li>
<li>功能：</li>
</ol>
<ul>
<li>作业控制：在 hadoop 中每个应用程序被表示成一个作业，每个作业又被分成多个任务，JobTracker 的作业控制模块则负责作业的分解和状态监控。最重要的是状态监控：主要包括TaskTracker状态监控、作业状态监控和任务状态监控。主要作用：容错和为任务调度提供决策依据。</li>
<li>资源管理</li>
</ul>
<h3 id="TaskTracker-剖析"><a href="#TaskTracker-剖析" class="headerlink" title="TaskTracker 剖析"></a>TaskTracker 剖析</h3><ol>
<li>概述：TaskTracker 是 JobTracker 和 Task 之间的桥梁，一方面，从 JobTracker 接受并执行各种命令：运行任务、提交任务、杀死任务等；另一方面，将本地节点上各个任务的状态通过心跳周期性汇报给 JobTracker。TaskTracker与JobTracker和Task之间采用RPC协议进行通信。</li>
<li>功能：</li>
</ol>
<ul>
<li>汇报心跳：Tracker周期性将所有节点上各种信息通过心跳机制汇报给JobTracker。这些信息包括两部分：<br>a. 机器级别信息：节点健康情况、资源使用情况等<br>b. 任务级别信息：任务执行进度、任务运行状态等</li>
<li>执行命令：JobTracker 会给 TaskTracker 下达各种命令，主要包括：启动任务、提交任务、杀死任务、杀死作业和重新初始化。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/JobTracker-和-TaskTracker-概述/" data-id="cj0bwefw2002mvopvmu8hu7uz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-浅谈-JobTracker-和-TaskTracker" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/浅谈-JobTracker-和-TaskTracker/" class="article-date">
  <time datetime="2016-11-26T03:47:30.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/浅谈-JobTracker-和-TaskTracker/">浅谈 JobTracker 和 TaskTracker</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>JobTracker 对应于 NameNode。TaskTracker 对应于 DataNode。<br>DataNode 和 NameNode 是针对数据存放而言的，JobTracker 和 TaskTracker 是对于 MapReduce 执行而言的。</p>
<p>MapReduce 中有几个主要概念：JobClient、JobTracker和TaskTracker。MapReduce 整体上可以分为这么几条执行线索：</p>
<ol>
<li>JobClient 会在用户端通过 JobClient 类将应用已经配置参数打包成 jar 文件存储到 HDFS，并把路径提交到 JobTracker，然后由 JobTracker 创建每一个 Task（即MapTask和ReduceTask），并将他们分发到各个 TaskTracker 服务中去执行</li>
<li>JobTracker 是一个 master 服务，软件启动之后 JobTracker 接受 Job，负责调度 Job 的每一个子任务 task 运行于 TaskTracker 上，并监控他们，如果发现有失败的 task 就重新运行它。一般情况下应该把 JobTracker 部署在单独的机器上。</li>
<li>TaskTracker 是运行在多个节点上的 slaver 服务，TaskTracker 主动与 JobTracker 通信，接受作业，并负责执行每一个任务。TaskTracker 都需要运行在 HDFS 的 DataNode 上。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/浅谈-JobTracker-和-TaskTracker/" data-id="cj0bweg3p00bmvopvnq354lw7" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-MapReduce" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-MapReduce/" class="article-date">
  <time datetime="2016-11-26T02:35:50.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-MapReduce/">Hadoop MapReduce</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>MapReduce 是一种编程模型，用于大规模数据级（大于 1TB）的并行运算。概念“Map（映射）”和“Reduce（归约）”是它们的主要思想。谷歌在 2004 年发表了可以分析大量数据的 MapReduce 算法。每当你听到“大数据”这个词时，它指的是因为太大而让仅仅一台机器难以有效存储或分析的问题。MapReduce 通过把计算量分配给不同的计算机群，能够解决大部分和大数据有关的分析问题。Hadoop 提供了最受欢迎的利用 MapReduce 算法来管理大数据的开源方式。</p>
<p>所以通常来说，每当听到“大数据”，那也许意味着 Hadoop 被用来存储数据，也通常意味着数据的抽取和检索是用的 MapReduce。</p>
<h3 id="拆分-MapReduce-算法"><a href="#拆分-MapReduce-算法" class="headerlink" title="拆分 MapReduce 算法"></a>拆分 MapReduce 算法</h3><p>MapReduce 合并了两种经典函数：</p>
<p>映射（Mapping）：对集合里的每个目标应用同一个操作。即，如果你相把表单里的每个单元格乘以二，那么把这个函数单独的应用到每个单元格上的操作就属于 mapping。<br>化简（Reducing）：遍历结合中的元素来返回一个综合的结果。即，“输出表单里的一列数字的和”这个任务属于reducing。</p>
<h3 id="MapReduce-算法例子"><a href="#MapReduce-算法例子" class="headerlink" title="MapReduce 算法例子"></a>MapReduce 算法例子</h3><p>你想数一摞牌中有多少张黑桃，直观的方式是一张一张检查并且输出有多少张黑桃。MapReduce 方法则是：</p>
<ol>
<li>给在座的所有玩家分配这摞牌</li>
<li>让每个玩家数自己手中的牌有几张是黑桃，然后把这个数目汇报给你</li>
<li>你把所有玩家告诉你的数字加起来，得到最后的结果</li>
</ol>
<p>这不是一个严谨的例子，在这个例子中，人代表计算机，因为他们同时工作，所以他们是一个集群。在大多数实际应用中，我们假设数据已经在每台计算机上了-也就是说把牌分发并不是 MapReduce 的第一步。（事实上，在计算机集群中如何存储文件是 Hadoop 的真正核心。）<br>通过把牌分给多个玩家并且让他们各自数数，你就在并行执行运算，因为每个玩家都在同时计算。这同时把这项工作变成了分布式，因为多个不同的人在解决同一个问题的过程中并不需要知道他们的邻居在干什么。<br>通过告诉每个人数数，你对一项检查每张牌的任务进行了映射。你不会让他们把黑桃牌递给你，而是让他们把你想要的东西化简为一个数字。<br>如果有足够的人的话，问一些更有趣的问题就相当简单了-比如“一摞牌的平均值是什么”。你可以通过合并“所有牌的值的和是什么”及“我们有多少张牌”这两个问题来得到答案。用这个和除以牌的张数就得到了平均值。</p>
<h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><p>MapReduce 通过把对数据集的大规模操作分发给网络上的每个节点实现可靠性；每个节点会周期性的返回它所完成的工作和最新的状态。如果一个节点保持沉默超过一个预设的时间间隔，主节点记录下这个节点状态为死亡，并把分配给这个节点的数据发到别的节点。</p>
<p>MapReduce 提供了以下的主要功能：</p>
<ol>
<li>数据划分和任务调度：</li>
</ol>
<p>系统自动将一个作业（Job）待处理的大数据划分为很多数据块，每个数据块对应于一个计算任务（Task），并自动调去计算节点来处理相应的数据块。作业和任务调度功能主要负责分配和调度计算节点（Map节点或Reduce节点），同时负责监控这些节点的执行状态，并负责Map节点指定的同步控制。</p>
<ol>
<li>数据/代码互定位：</li>
</ol>
<p>为了减少数据通信，一个节本原则是本地化数据处理，即一个计算节点尽可能处理其本地磁盘上所分布存储的数据，这实现了代码向数据的迁移；当无法进行这种本地化处理数据处理时，再寻找其它可用节点并将数据从网络上送到该节点（数据向代码迁移），但尽可能从数据所在的本地机架上寻找可用节点以减少通信延迟。</p>
<ol>
<li>系统优化</li>
</ol>
<p>为了减少数据通信开销，中间结果数据进入 Reduce 节点前会进行一定的合并处理；一个 Reduce 节点所处理的数据可能会来自多个 Map 节点，为了避免 Reduce 计算阶段发生数据相关性，Map 节点输出的中间结果需要使用一定的策略进行适当的划分处理，保证相关性数据发送到同一个 Reduce 节点；此外，系统还进行一些计算性能优化处理，如对最慢的计算任务采用多备份执行、选最快完成者作为结果。</p>
<ol>
<li>出错检测和恢复</li>
</ol>
<p>以低端商用服务器构成的大规模MapReduce 计算集群中，节点硬件（主机、磁盘、内存等）出错和软件出错是常态，因此 MapReduce 需要能检测并隔离出错点，并调度分配新的节点接管出错节点的计算任务。同时，系统还将维护数据存储的可靠性，用多备份冗余存储机制提高数据存储的可靠性，并能及时检测和恢复出错的数据。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-MapReduce/" data-id="cj0bwefv0001tvopvi9qdgcx4" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hadoop-启动、关闭" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/26/Hadoop-启动、关闭/" class="article-date">
  <time datetime="2016-11-26T01:08:50.000Z" itemprop="datePublished">2016-11-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/26/Hadoop-启动、关闭/">Hadoop 启动、关闭</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="适用版本"><a href="#适用版本" class="headerlink" title="适用版本"></a>适用版本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@master hadoop]# hadoop version</span><br><span class="line">Hadoop 3.0.0-alpha1</span><br><span class="line">Source code repository https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3</span><br><span class="line">Compiled by andrew on 2016-08-30T07:02Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum f3a9644139eac17acbb91bfce7f68e2</span><br><span class="line">This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar</span><br></pre></td></tr></table></figure>
<h2 id="参考地址"><a href="#参考地址" class="headerlink" title="参考地址"></a>参考地址</h2><p><a href="http://hadoop.apache.org/docs/r3.0.0-alpha1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Slaves_File" target="_blank" rel="external">http://hadoop.apache.org/docs/r3.0.0-alpha1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Slaves_File</a></p>
<h2 id="Hadoop-Startup"><a href="#Hadoop-Startup" class="headerlink" title="Hadoop Startup"></a>Hadoop Startup</h2><ol>
<li>要启动 Hadooop cluster，需要同时启动 HDFS 和 YARN cluster.<br>第一次打开 HDFS，它必须先格式化它。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
<ol>
<li>如果 etc/hadoop/workers 与 ssh 信任已经配置好了，所有的 HDFS processes 可以使用单一的脚本来启动</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/start-dfs.sh   #在NameNode 节点运行</span><br></pre></td></tr></table></figure>
<p>也可以逐个节点来启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hdfs --daemon start namenode   #Start HDFS NameNode</span><br><span class="line">$HADOOP_HOME/bin/hdfs --daemon start datanode   #Start HDFS DataNode</span><br></pre></td></tr></table></figure>
<ol>
<li>如果 etc/hadoop/workers 与 SSH 信任已经配置好了，所有的 YARN processes 可以使用单一的脚本来启动</li>
</ol>
<p>YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。运行于 MapReduce 之上，提供了高可用性、高扩展性。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>也可以逐个节点来启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/yarn --daemon start resourcemanager    #使用如下命令运行指定的资源管理程序</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon start nodemanager   #在每个yarn节点启动NodeManager</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon start proxyserver</span><br></pre></td></tr></table></figure>
<ol>
<li>在指定的服务器运行如下命令启动 MapReduce JobHistory Server</li>
</ol>
<p>开启历史服务器，才能在 Web 中查看任务运行（注意，这里是查看，默认是全部会记录，只有开启后才能查看）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop-ShutDown"><a href="#Hadoop-ShutDown" class="headerlink" title="Hadoop ShutDown"></a>Hadoop ShutDown</h2><ol>
<li>如果 etc/hadoop/workers 与 SSH 信任已经配置好了，使用如下命令停止所有的 HDFS processes</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/stop-dfs.sh    #在 NameNode 节点运行</span><br></pre></td></tr></table></figure>
<p>同启动的时候一样，也可以逐个节点停止：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hdfs --daemon stop namenode    # 在 NameNode 节点运行</span><br><span class="line">$HADOOP_HOME/bin/hdfs --daemon stop datanode    # 在 DataNode 节点运行</span><br></pre></td></tr></table></figure>
<ol>
<li>如果 etc/hadoop/workers 与 SSH 信任已经配置好可，使用如下命令停止所有 YARN processes</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>
<p>也可以逐个节点停止：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/yarn --daemon stop resourcemanager</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon stop nodemanager</span><br><span class="line">$HADOOP_HOME/bin/yarn --daemon stop proxyserver</span><br></pre></td></tr></table></figure>
<ol>
<li>停止 MapReduce JobHistory Server</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/26/Hadoop-启动、关闭/" data-id="cj0bwefv5001uvopv3co5vrwy" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-SSH-无密码登录节点" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/25/SSH-无密码登录节点/" class="article-date">
  <time datetime="2016-11-25T07:29:47.000Z" itemprop="datePublished">2016-11-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/25/SSH-无密码登录节点/">SSH 无密码登录节点</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在配置 Hadoop 的过程中一个必要的步骤是配置 Mster 节点可以无密码 SSH 登录到各个 Slave 节点上。</p>
<p>如下说明配置步骤：</p>
<ol>
<li>生成 Master 节点的公匙（在 Master 节点的终端中执行）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh		#如果没有该目录，先执行一次 ssh localhost</span><br><span class="line">rm -rf ./id_rsa*	#删除之前生成的公钥（如果有）</span><br><span class="line">ssh-keygen -t rsa	#一直按回车就可以</span><br></pre></td></tr></table></figure>
<ol>
<li>配置 Master 节点可以无密码 SSH 本机（在 Master 节点的终端中执行）</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ./id_rsa.pub &gt;&gt;./authorized_keys</span><br></pre></td></tr></table></figure>
<p>完成后可执行 ssh Master 验证一下（可能需要输入 yes，成功后执行 exit 返回原来的终端）。</p>
<ol>
<li>在 Master 节点将公钥传送到各个 Slave 节点</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa.pub root@slave1:/root/</span><br></pre></td></tr></table></figure>
<ol>
<li>在 Slave 节点上，将 Master SSH 公匙加入授权</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/.ssh		#如果不存在该文件夹需要先创建，若存在则忽略</span><br><span class="line">cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys	</span><br><span class="line">rm ~/id_rsa.pub		#用完就可以删除了</span><br></pre></td></tr></table></figure>
<p>如果有其它 slave 节点，也要执行将 Master 公匙传送到其它 Slave 节点并授权的步骤。</p>
<hr>
<p>至此，在 Master 节点上就可以无密码 SSH 到各个 Slave 节点了。可以在 Master 节点上执行如下命令进行检验：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh slave1</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/25/SSH-无密码登录节点/" data-id="cj0bweg0h007jvopv5a0oi4p0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-查找通过Yum安装的Java的安装路径" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/25/查找通过Yum安装的Java的安装路径/" class="article-date">
  <time datetime="2016-11-25T03:46:47.000Z" itemprop="datePublished">2016-11-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Centos-7/">Centos 7</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/25/查找通过Yum安装的Java的安装路径/">查找通过Yum安装的Java的安装路径</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>很多需要 Javac 的程序依赖于 JAVA_HOME 环境变量。<br>如果是手工下载源码安装的JDK，很容易知道 JAVA_HOME 的目录，那么 YUM 安装的 JDK，不需要配置 PATH，因为已经使用软链接做好了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon hadoop]# echo $PATH</span><br><span class="line">/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line">[root@bogon hadoop]# javac -version</span><br><span class="line">javac 1.8.0_111</span><br></pre></td></tr></table></figure>
<ol>
<li>YUM 安装 JDK</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y java*</span><br></pre></td></tr></table></figure>
<ol>
<li>查找 JAVA_HOME</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon hadoop]# whereis javac</span><br><span class="line">javac: /usr/bin/javac /usr/share/man/man1/javac.1.gz</span><br><span class="line">[root@bogon hadoop]# ls -l /usr/bin/javac</span><br><span class="line">lrwxrwxrwx. 1 root root 23 11月 23 12:11 /usr/bin/javac -&gt; /etc/alternatives/javac</span><br><span class="line">[root@bogon hadoop]# ls -l /etc/alternatives/javac</span><br><span class="line">lrwxrwxrwx. 1 root root 70 11月 23 12:11 /etc/alternatives/javac -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/bin/javac</span><br><span class="line">[root@bogon hadoop]# whereis java</span><br><span class="line">java: /usr/bin/java /usr/lib/java /etc/java /usr/share/java /usr/share/man/man1/java.1.gz</span><br><span class="line">[root@bogon hadoop]# ls -l /usr/bin/java</span><br><span class="line">lrwxrwxrwx. 1 root root 22 11月 23 12:07 /usr/bin/java -&gt; /etc/alternatives/java</span><br><span class="line">[root@bogon hadoop]# ls -l /etc/alternatives/java</span><br><span class="line">lrwxrwxrwx. 1 root root 73 11月 23 12:07 /etc/alternatives/java -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/jre/bin/java</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/25/查找通过Yum安装的Java的安装路径/" data-id="cj0bweg3m00bhvopvjag33e60" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据库镜像-主备切换" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/11/数据库镜像-主备切换/" class="article-date">
  <time datetime="2016-11-11T06:04:59.000Z" itemprop="datePublished">2016-11-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/11/数据库镜像-主备切换/">数据库镜像-主备切换</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ol>
<li>高性能状态-主备切换（主机服务停止）</li>
</ol>
<p>主机服务停止，镜像（备机）上执行下列命令后备机状态会变为：<strong>主机 挂起/正在还原…</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER FORCE_SERVICE_ALLOW_DATA_LOSS;</span><br></pre></td></tr></table></figure></p>
<p>此时如原主机再启动服务，会显示挂起状态。执行下列命令后状态会变为：<strong>镜像 已同步/正在还原…</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER RESUME;</span><br></pre></td></tr></table></figure></p>
<p>如果要从原镜像机（即现在的主机）手动切换回镜像状态，需执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER SAFETY FULL;</span><br></pre></td></tr></table></figure></p>
<p>即将运行模式改为高安全，这时状态就会变回最初的状态（即原始的主机和备机）</p>
<ol>
<li>高性能状态下-主备切换（主机网络断开）<br>在原始的主机、备机状态下，将主机网络断开，在备机（镜像）上执行下列命令同样可以实现主备切换：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER FORCE_SERVICE_ALLOW_DATA_LOSS;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>但是此时的备机（镜像）虽然成为了主机，其运行模式为高安全模式，需要手动切换到高性能模式下。然后将主机联网后，在主机上执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER DATABASE &lt;DatabaseName&gt; SET PARTNER RESUME;</span><br></pre></td></tr></table></figure></p>
<p>此时主机变为镜像机（镜像，已同步/正在还原…）</p>
<p>高安全模式下，将原主机服务停止，镜像机自动转为主机，但运行模式为高安全模式，此时镜像（相对于现在为主机）是不能调整运行模式的。即不能从高安全调整为高性能模式。只有当原主机网络连通或服务开始运行后在镜像（相对于现在为主机）才可以调整运行模式，同时这时也不允许强制执行。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/11/数据库镜像-主备切换/" data-id="cj0bweg3f00b5vopvnb7c3bev" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CentOS-系统时间与现在时间相差8小时解决方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/11/10/CentOS-系统时间与现在时间相差8小时解决方法/" class="article-date">
  <time datetime="2016-11-10T01:27:49.000Z" itemprop="datePublished">2016-11-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Centos-7/">Centos 7</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/11/10/CentOS-系统时间与现在时间相差8小时解决方法/">CentOS 系统时间与现在时间相差8小时解决方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天安装了一台 CentOS 7 系统，安装好之后发现时间与现在时间相差 8 小时，具体表现如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost 0900]# date</span><br><span class="line">2016年 11月 10日 星期四 17:24:18 CST</span><br><span class="line">[root@localhost 0900]# date -u</span><br><span class="line">2016年 11月 10日 星期四 09:24:22 UTC</span><br></pre></td></tr></table></figure>
<p>这是由于我们在安装系统的时候时区是上海，而 CentOS 默认 bios 时间是 UTC 时间，所以相差 8 小时。这个时候 bios 时间和系统时间不一致，一个代表 UTC 时间，一个代表 CST （+8时区），即上海时间。</p>
<p>下面是同步时间的解决方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime # Linux 时区设置为上海</span><br><span class="line">ntpdate asia.pool.ntp.org # 对准时间，需要先安装ntp服务器，yum install ntp</span><br><span class="line">/sbin/hwclock --systohc # 设置硬件时间和系统时间一致并校准</span><br></pre></td></tr></table></figure>
<p>至此，linux 系统时间和计算机硬件时间都是都是 cst 时区了，并且为上海时区。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost 0900]# date -u</span><br><span class="line">2016年 11月 10日 星期四 01:25:25 UTC</span><br><span class="line">[root@localhost 0900]# date</span><br><span class="line">2016年 11月 10日 星期四 09:25:27 CST</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/11/10/CentOS-系统时间与现在时间相差8小时解决方法/" data-id="cj0bweft4000hvopvw803wnp8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-CREATE-INDEX" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/27/CREATE-INDEX/" class="article-date">
  <time datetime="2016-10-27T03:50:13.000Z" itemprop="datePublished">2016-10-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/27/CREATE-INDEX/">CREATE INDEX</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CREATE-INDEX"><a href="#CREATE-INDEX" class="headerlink" title="CREATE INDEX"></a>CREATE INDEX</h2><p>为给定表或视图创建索引。<br>只有表或视图的所有者才能为表创建索引。表或视图的所有者可以随时创建索引，无论表中是否有数据。可以通过指定限定的数据库名称，为另一个数据库中的表或视图视窗索引。</p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE [ UNIQUE ] [ CLUSTERED | NONCLUSTERED ] INDEX index_name</span><br><span class="line">    ON &#123; table | view &#125; ( column [ ASC | DESC ] [ ,...n ] )</span><br><span class="line">[ WITH &lt; index_option &gt; [ ,...n] ]</span><br><span class="line">[ ON filegroup ]</span><br><span class="line"></span><br><span class="line">&lt; index_option &gt; ::=</span><br><span class="line">    &#123; PAD_INDEX |</span><br><span class="line">        FILLFACTOR = fillfactor |</span><br><span class="line">        IGNORE_DUP_KEY |</span><br><span class="line">        DROP_EXISTING |</span><br><span class="line">    STATISTICS_NORECOMPUTE |</span><br><span class="line">    SORT_IN_TEMPDB </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><h4 id="UNIQUE"><a href="#UNIQUE" class="headerlink" title="UNIQUE"></a>UNIQUE</h4><p>为表或视图创建唯一索引（不允许存在索引值相同的两行）。视图上的聚簇索引必须是 UNIQUE 索引。<br>在创建索引时，如果数据已存在，SQL Server 会检查是否有重复值，并在每次使用 INSERT 或 UPDATE 语句添加数据时进行这种检查。<br>如果存在重复的键值，将取消 CREATE INDEX 语句，并返回错误信息，给出第一个重复值。<br>如果存在唯一索引，那么会产生重复键值的 UPDATE 或 INSERT 语句将回滚，SQL Server 将显示错误信息。即使 UPDATE 或 INSERT 语句更改了很多行但只产生一个重复值，也会出现这种情况。<br>如果在有唯一索引并指定了 IGNORE_DUP_KEY 子句情况下输入数据，则只有违反 UNIQUE 索引才会失败。在处理 UPDATE 语句时，IGNORE_DUP_KEY 不起作用。<br>SQL Server 不允许为已经包含重复值的列创建唯一索引，无论是否设置了 IGNORE_DUP_KEY。如果尝试这样做，SQL Server 会显示错误信息；重复值必须先删除，才能为这些列创建唯一索引。</p>
<h4 id="CLUSTERED"><a href="#CLUSTERED" class="headerlink" title="CLUSTERED"></a>CLUSTERED</h4><p>创建一个对象，其中行的物理排序与索引排序相同，并且聚簇索引的最低一级（页级）包含实际的数据行。一个表或视图只允许同时有一个聚簇索引。具有聚簇索引的视图称为索引视图。必须先为视图创建唯一聚簇索引，然后才能为该视图定义其它索引。</p>
<p>因为按照定义，聚簇索引的页级与其数据页相同，所以创建聚簇索引时使用 ON filegroup 子句实际上会将表从创建该表所用的文件移到新的文件组中。在特定的文件组上创建表或索引之前，应确认哪些文件组可用并且有足够的空间供索引使用。文件组的大小必须至少是整个表所需空间的 1.2 倍，这一点很重要。</p>
<h4 id="NONCLUSTERED"><a href="#NONCLUSTERED" class="headerlink" title="NONCLUSTERED"></a>NONCLUSTERED</h4><p>创建一个指定表的逻辑排序的对象。对于非聚簇索引，行的物理排序独立于索引排序。非聚簇所应的页级包含索引行。每个索引行均包含非聚簇键值和一个或多个行定位器（指向包含该值的行）。如果表没有聚簇索引行，行定位器就是行的磁盘地址。如果表有聚簇索引，行定位器就是该行的聚簇索引键。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/10/27/CREATE-INDEX/" data-id="cj0bweft8000jvopvwu7hy4lt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-数据库中聚簇索引和非聚簇索引的区别" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/27/数据库中聚簇索引和非聚簇索引的区别/" class="article-date">
  <time datetime="2016-10-27T02:15:04.000Z" itemprop="datePublished">2016-10-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/27/数据库中聚簇索引和非聚簇索引的区别/">数据库中聚簇索引和非聚簇索引的区别</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在&lt;&lt;数据库原理&gt;&gt;里面，对聚簇索引的解释是：聚簇索引的顺序就是数据的物理存储顺序，而对非聚簇所应的解释是：索引顺序与数据物理排序顺序无关。正是因为如此，所以一个表最多只能有一个聚簇索引。</p>
        
          <p class="article-more-link">
            <a href="/2016/10/27/数据库中聚簇索引和非聚簇索引的区别/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://ttlop.com/2016/10/27/数据库中聚簇索引和非聚簇索引的区别/" data-id="cj0bweg3c00b0vopv94nie6m7" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Apache/">Apache</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Bat/">Bat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Centos-7/">Centos 7</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HTTP/">HTTP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/HUAWEI/">HUAWEI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hyper-V/">Hyper-V</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Iptables/">Iptables</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Microsoft-SQL-Server/">Microsoft SQL Server</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MikroTik/">MikroTik</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mysql/">Mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nagios/">Nagios</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nginx/">Nginx</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PHP/">PHP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Postfix/">Postfix</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Redis/">Redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zabbix/">Zabbix</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/03/16/华为S系列交换机配置SSH登录/">华为S系列交换机配置SSH登录</a>
          </li>
        
          <li>
            <a href="/2017/02/15/Zabbix-监控-Windows-的-CPU-百分比/">Zabbix 监控 Windows 的 CPU 百分比</a>
          </li>
        
          <li>
            <a href="/2017/02/14/Linux-访问-Windows-共享文件夹的两种方法/">Linux 访问 Windows 共享文件夹的两种方法</a>
          </li>
        
          <li>
            <a href="/2016/12/13/HTTP-请求/">HTTP 请求</a>
          </li>
        
          <li>
            <a href="/2016/12/13/HTTP-协议基础/">HTTP 协议基础</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 XiaoYong Hu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/About" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>